#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass /home/user/Downloads/integration-problem-set/pres/svjour3
\options twocolumn
\use_default_options true
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "unicode=true"
\papersize a4paper
\use_geometry false
\use_package amsmath 2
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\rightmargin 5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
mnras}{MNRAS}
\end_layout

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
apjl}{ApJ}
\end_layout

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
apj}{ApJL}
\end_layout

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
aap}{A
\backslash
&A}
\end_layout

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
aj}{AJ}
\end_layout

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
procspie}{SPIE}
\end_layout

\begin_layout Plain Layout


\backslash
newcommand{
\backslash
mdash}{-}
\end_layout

\begin_layout Plain Layout


\backslash
journalname{Publications of the Astronomical Society of the Pacific}
\end_layout

\begin_layout Plain Layout


\backslash
institute{
\end_layout

\begin_layout Plain Layout

Millenium Institute of Astrophysics, Vicu
\backslash
~{n}a.
 MacKenna 4860, 7820436 Macul, Santiago, Chile
\end_layout

\begin_layout Plain Layout


\backslash

\backslash

\end_layout

\begin_layout Plain Layout

Pontificia Universidad Católica de Chile, Instituto de Astrofísica, Casilla
 306, Santiago 22, Chile
\end_layout

\begin_layout Plain Layout


\backslash

\backslash

\end_layout

\begin_layout Plain Layout

Excellence Cluster Universe, Boltzmannstr.
 2, D-85748, Garching, Germany
\end_layout

\begin_layout Plain Layout


\backslash

\backslash

\end_layout

\begin_layout Plain Layout


\backslash
email{johannes.buchner.acad@gmx.com}
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout


\backslash
titlerunning{A space of Bayesian inference parameter spaces}
\end_layout

\begin_layout Plain Layout

%@arxiver{outimg_noise0.2.pdf,plotscaling.pdf,plotcontour_5.pdf}
\end_layout

\end_inset


\end_layout

\begin_layout Title
A space of spaces in the space sciences: parametric Bayesian inference in
 astronomy, cosmology and particle physics
\end_layout

\begin_layout Author
Johannes Buchner
\end_layout

\begin_layout Date
.
\end_layout

\begin_layout Abstract
d
\end_layout

\begin_layout Keywords
S
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Fitting parametric models to experimental data is one of the key methods
 to infer physical parameters.
 In physics, investigation of distant processes is possible by modelling
 the measurement process accurately.
 Here, we focus on problems where the model has continuous parameters with
 predefined prior ranges, and where a likelihood function has been derived
 to compare the model prediction to data.
 Some examples include fitting the power spectrum of the Cosmic Microwave
 Background (CMB) with Dark Energy and Cold Dark Matter (
\begin_inset Formula $\lambda$
\end_inset

CDM) cosmologies, fitting time series of the radial velocity of a host star
 gravitationally pulled by its exoplanets, dissecting multiple components
 in spectra and population inference from uncertain measurements of many
 individual objects, such as luminosity or mass functions.
 The plausible ranges of model parameters that match the data are typically
 tested in a Bayesian framework (where prior and likelihood are specified),
 with Monte Carlo samplers.
\end_layout

\begin_layout Standard
Monte Carlo sampling methods of varying complexity have been developed over
 the last decades.
 This includes variations of Markov Chain Monte Carlo (MCMC), Particle Monte
 Carlo (PMC), Importance Samplers (IS) and Nested Samplers (NS).
 Specific implementations specify the initialisation, exploration strategy
 (e.g., proposal function) and termination criterion.
 These are often tuned for the application.
 Reliable parameter recovery of a method can be tested by Monte Carlo simulating
 new datasets, and analysing them.
 An alternative are toy inference problems that approximate features of
 the real problem.
 These can be more easily understood and more rapidly analysed.
 Given the diversity of algorithms and inference problems, it is interesting
 to consider whether a different algorithm can perform well on the same
 problem, and whether the currently used algorithm can be transferred to
 another problem.
 This work is focusing on the applicability of Monte Carlo Samplers over
 different types of inference problems.
\end_layout

\begin_layout Standard
Inference problems differ substantially by the posterior distribution that
 a Monte Carlo sampler has to explore.
 The main characteristics of problems include (1) the number of model parameters
, (2) whether the posterior shape is similar to a gaussian, (3) whether
 the posterior has light or heavy tails, (4) how small the posterior is
 compared to the prior (i.e., how informative the data are), (5) whether some
 parameters remain unconstrained while others are highly constrained, (6)
 whether the posterior has multiple, disconnected peaks.
\end_layout

\begin_layout Standard
This work puts forward three main contributions: (1) A systematic classification
 of inference problems based on five characteristics.
 (2) A diverse set of real and toy inference problems that cover the classificat
ion space well.
 (3) A preliminary investigation of a few samplers over the classification
 space to identify the regions where they perform well.
 Here, performance is primarily defined by correctness (difference between
 true posterior and inferred posterior), and secondarily by efficiency (number
 of model evaluations required).
 Practitioners can then pick an appropriate algorithm based on the type
 of problem at hand.
\end_layout

\begin_layout Standard
Out of scope: hierarchical bayesian models –> see Buchner+15, Baronchelli+20.
 Extremely multimodal problems (10^5 minima like Potts, Lennart-Jones potentials
) –> see for example 
\begin_inset CommandInset citation
LatexCommand cite
key "Pfeifenberger2016"
literal "false"

\end_inset

.
 transdimensional models: 
\begin_inset CommandInset citation
LatexCommand cite
key "Brewer2014"
literal "false"

\end_inset

 computationally costly.
 Additional potential characteristic: whether the maximum likelihood point
 is inside the 99% HDI.
\end_layout

\begin_layout Section
Inference Problem Classification Space
\end_layout

\begin_layout Standard
Various difficulties are encountered by different sub-disciplines.
 Here we specify six characteristics and give a mathematical definition
 for each.
\end_layout

\begin_layout Subsection
Dimensionality
\end_layout

\begin_layout Standard
In astrophysics, fitting problem dimensionalities range from 1 to millions
 parameters.
 Examples of extremely high-dimensional problems include pixel reconstructions
 (e.g., ) and .
 With more parameters, the possible combinations of parameter values rises
 exponentially (the curse of dimensionality).
 This makes the problem complex to explore and distances between parameter
 space points meaningless.
 
\end_layout

\begin_layout Standard
Here we defined three common sub-groups: low-dimensional (
\begin_inset Formula $d=2-9$
\end_inset

), mid-dimensional (
\begin_inset Formula $d=10-29$
\end_inset

) and high-dimension (
\begin_inset Formula $d\geq30$
\end_inset

).
 The boundaries are set near where simple and more sophisticated ideas of
 geometric sampling start failing.
 Extremely high dimensions (
\begin_inset Formula $d\gg100$
\end_inset

) are not the focus of this work.
 We note that these virtually always require the derivatives of likelihood
 functions to effectively navigate the parameter space.
 The availability of likelihood derivatives could be considered an additional
 classification category.
\end_layout

\begin_layout Subsection
Information gain
\end_layout

\begin_layout Standard
Depending on the data quality of the experiment, the posterior may be a
 tiny region of the prior, or be identical with the prior.
 This can be quantified by the Kullback-Leibler divergence, or surprise,
 between the two probability distributions:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
D_{\mathrm{KL}}=\int\pi(\theta)\ln\frac{\pi(\theta)}{P(\theta)}d\theta
\]

\end_inset

Here, 
\begin_inset Formula $\pi$
\end_inset

 and 
\begin_inset Formula $P$
\end_inset

 give the prior and posterior over the parameter vector space 
\begin_inset Formula $\theta$
\end_inset

.
 In the case of a base-e logarithm, the unit of 
\begin_inset Formula $D_{\mathrm{KL}}$
\end_inset

is nats, and approximately means how many e-foldings it takes to cut the
 prior until the posterior is reached.
 Finding that small region can be a challenge for sampling algorithms (and
 maximum likelihood minimizers).
\end_layout

\begin_layout Standard
In practice, the information gain is already computed by nested sampling
 algorithms internally for error estimation, and we adopt that method as
 a measurement.
 Also, the information gain is related to the number of iterations of the
 nested sampling algorithms needs to zoom in until the likelihood appears
 flat.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Note Note
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/logs/asymgaussRNS-4d/simplified_posterior2d.pdf
	height 4cm

\end_inset


\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/logs/cosmology/simplified_posterior2d.pdf
	height 4cm

\end_inset


\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/logs/exorv-rvs_0004.txt-1/simplified_posterior2d.pdf
	height 4cm

\end_inset


\begin_inset Graphics
	filename /home/user/Downloads/mininest/examples/logs_full_tests/dist-betaRNS-10d-harm100-adaptmove-distance/simplified_posterior2d.pdf
	height 4cm

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/logs/ligo/simplified_posterior2d.pdf
	height 5cm

\end_inset


\begin_inset Graphics
	filename /home/user/Downloads/mininest/examples/logs_full_tests/stdfunnel-gamma0.95-RNS-2d/simplified_posterior2d.pdf
	height 5cm

\end_inset


\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/logs/rosenRNS-2d/simplified_posterior2d.pdf
	height 5cm

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/logs/eggbox/simplified_posterior2d.pdf
	height 4.5cm

\end_inset


\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/logs/xrayspectrum10-0.01/simplified_posterior2d.pdf
	height 4.5cm

\end_inset


\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/logs/loggammaRNS-2d/simplified_posterior2d.pdf
	height 4.5cm

\end_inset


\begin_inset Graphics
	filename /home/user/Downloads/mininest/examples/logs_full_tests/testmultisine-contrast100-N40RNS-2d-harm100-adaptmove-distanceRNS-5d-harm100-adaptmove-distanceRNS-8d-harm100-adaptmove-distanceRNS-11d-harm100-adaptmove-distance/simplified_posterior2d.pdf
	height 4.5cm

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:pairwise-posterior"

\end_inset

Selected pair-wise posterior distributions from some of our problems.
 These illustrate non-linear degeneracies (e.g., middle panels), unequal axes
 (e.g., left-most and right-most top panels), multi-modality (bottom panels).
 The loggamma problem (third panel, bottom row) also has heavy tails towards
 the left.
 Some parameters are uninformative (e.g., param1 in top right panel) or at
 the prior parameter edge (middle left panel, ratio 
\begin_inset Formula $q\geq1$
\end_inset

, top right panel, 
\begin_inset Formula $0\leq\mathrm{param2}\leq1$
\end_inset

).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Multi-modality
\end_layout

\begin_layout Standard
When data can be explained by different combinations of processes with similar
 quality, the posterior exhibits multiple peaks.
 This is common in fits of multiple components with (nearly-)interchangable
 predictions, paired with poor descrimination power of the data.
 Algorithms based on local jumps can find multiple modes difficult to navigate,
 because a proposal tuned to a single mode may propose into another distant
 mode with vanishing probability.
 The bottom row of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

 shows examples of multimodal distributions.
\end_layout

\begin_layout Standard
To mathematically define multi-modality, a threshold criterion is needed
 to define disconnectedness.
 In principle any clustering algorithm can be used.
 For simplicity and reproducibility, we adopt a simple approach.
 First, histograms of the marginal posteriors are histogrammed into 20 bins.
 Bins with values less than 1/5 of the peak are considered 
\begin_inset Quotes eld
\end_inset

empty
\begin_inset Quotes erd
\end_inset

.
 Gaps are identified, and thresholds that bracket the peaks extracted.
 This is repeated for every dimension.
 Secondly, all combinations of brackets are computed.
 These are the clusters.
 If posterior samples are members of multiple clusters, the clusters are
 merged.
 The number of remaining clusters is the number of modes of the problem.
\end_layout

\begin_layout Subsection
Non-Gaussianity
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/evaluateproblems_volcurve.pdf
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:volcurve"

\end_inset

Probability fraction enclosed as a function of prior volume.
 From the highest likelihood regions outwards, the volume is increased from
 left to right until the entire prior space (
\begin_inset Formula $V=1$
\end_inset

) is enclosed.
 The median (cross) indicates how large the posterior volume is relative
 to the prior, and is related to the 
\emph on
information gain
\emph default
.
 Quantiles at 5% and 95% indicated as circles indicate the shell where most
 probability mass is enclosed.
 This is related to the 
\emph on
tail weight
\emph default
.
 Some problems show wide transitions (e.g., green dashed) relative to a gaussian
 (blue dashed).
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The posterior is often shaped like a gaussian, in particular when the data
 quality is high, the model is linear in its parameters and the true value
 is not at a boundary (Wilks' theorem, 
\begin_inset CommandInset citation
LatexCommand cite
key "wilks1938large"
literal "false"

\end_inset

).
 Additionally, the elliptical shape of gaussian contours can be easily caused
 by likelihoods employing ellipsoidal distributions, such as Gaussians.
 For this reason, some algorithms are constructed to behave optimally when
 the posterior is Gaussian (see e.g., Laplace approximation).
\end_layout

\begin_layout Standard
The gaussianity of a posterior can be easily measured through the surprise
 from the posterior to a best-fitting multi-variate Gaussian.
 We obtain a suitable gaussian from the mean and covariance of the posterior
 samples.
 In multi-modal cases, the posterior is non-gaussian by definition.
\end_layout

\begin_layout Subsection
Tail weight
\end_layout

\begin_layout Standard
While the posterior may have ellipsoidal contours like a Gaussian, it may
 decline steeper or shallower than this.
 For example, when outliers are allowed (e.g., in student-t distribution or
 explicit outlier modelling), the wings of the posterior can be wide.
 Some algorithms require a long time to explore the tails of distributions
 if they deviate from square-exponential declines.
 Another cause of heavy tails is when most data points are fitted well by
 one component, and a minor component relevant for a small data subset improves
 the fit slightly (for example, in blind spectral line searches on top of
 a continuum).
 This leads to a phase transition, where the parameter space to be explored
 changes rapidly (with small likelihood change) from a wide volume to a
 narrow volume.
 This is difficult for many samplers.
\end_layout

\begin_layout Standard
To quantify how the weight is distributed over the prior volume, we compute
 the prior volume above a given likelihood threshold.
 This is illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:volcurve"

\end_inset

.
 We compute the 
\begin_inset Formula $5\%$
\end_inset

 and 
\begin_inset Formula $95\%$
\end_inset

 quantiles of the volume ranges where most of the probability mass resides,
 and compute the tail weight as:
\begin_inset Formula 
\[
\mathrm{TW}=\log\frac{V_{5\%}}{V_{95\%}}
\]

\end_inset

In practice, the mapping of volume and likelihood, as well as the normalising
 constant, the marginal likelihood integrated over volume shrinkages, is
 already computed internally in nested sampling.
 We cap the value at 
\begin_inset Formula $\mathrm{TW}=\log10\times d$
\end_inset

.
\end_layout

\begin_layout Subsection
Parameter Inequality
\end_layout

\begin_layout Standard
Some model parameters may alter the model prediction strongly, while others
 have more minute implications.
 Because of this, the posterior of some parameters can be consistent with
 the prior (no information learnt), while for others, its plausible range
 has diminished by orders of magnitude.
 Proposal symmetric over parameter space directions then perform poorly.
 The top row of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

 shows such examples in pairs of parameters.
 
\end_layout

\begin_layout Standard
We quantify the inequality of parameters in problems by marginal posterior
 standard deviations:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathrm{IE}=\log\frac{\max\sigma_{i}}{\min\sigma_{i}}
\]

\end_inset

If all parameters have similar posterior uncertainties, 
\begin_inset Formula $\mathrm{IE}=0$
\end_inset

.
 We cap this value to at most 
\begin_inset Formula $\mathrm{IE}=10$
\end_inset

.
\end_layout

\begin_layout Section
Model survey
\end_layout

\begin_layout Standard
To cover most of the problem space, we collect inference problems published
 in the literature and available in open-source physics packages.
 Section
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Real-problems"

\end_inset

 first introduces real-world problems, which form the main contribution
 of this work.
 Simplified mock problems with generated data sets that approximate real-world
 problems are presented in Appendix
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Mock-problems"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Appendix
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Toy-problems"

\end_inset

 introduces artificial toy problems.
 
\end_layout

\begin_layout Standard
For each problem, the likelihood function 
\begin_inset Formula $L(\theta)$
\end_inset

 is defined together with prior distribution 
\begin_inset Formula $\pi(\theta)$
\end_inset

 over the parameter space.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
wide true
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
input{../evaluateproblems.tex}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
List of problems analysed.
 The columns describe (1) the field of space sciences where the inference
 problem occurs, (2) name, (3) dimensionality, (4) model evaluation cost
 in milliseconds, (5) information gain, (6) tail weight, (7) asymmetry of
 the information gains of the model parameters, (8) information loss if
 the posterior is approximated by a Gaussian, (9) phase transition.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "subsec:Real-problems"

\end_inset


\end_layout

\begin_layout Subsection
Exoplanet detection from Radial Velocity data
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/exoplanet/rvs_0005.txt.pdf
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Sine-data-1"

\end_inset

Exoplanet Doppler shift time series data (blue).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
One of the most efficient ways to detect exoplanets is through changes in
 the line-of-sight (radial) velocity of individual stars, as the tug of
 planets gravitationally accelerates them (Doppler shift).
 A planetary system leads to a complex overlay of periodic velocity changes.
 Additionally, the measurement of velocities is uncertain, in part because
 of the instrument accuracy and precision, and in part because the spectral
 emission lines used to measure Doppler shifts can be unstable due to stellar
 activity.
 That latter process has been modeled with Gaussian processes in recent
 years.
\end_layout

\begin_layout Standard
Here we adopt the problem setup of the Extreme Precision Radial Velocity
 III challenge 
\begin_inset CommandInset citation
LatexCommand cite
key "Nelson2020"
literal "false"

\end_inset

.
 They simulated several artificial exoplanet systems containing two planets,
 with a Gaussian process and realistic observation time sampling.
 The challenge participants were asked to compute the Bayesian marginal
 likelihoods of each data set assuming that the true number of planets was
 0, 1, 2 or 3.
 Participants did not know the true simulation input, but they were told
 the exact Gaussian noise properties.
 Here we repeat this exercise, for their dataset 5 (shown in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Sine-data-1"

\end_inset

).
 The exact specification of this problem is defined in 
\begin_inset CommandInset citation
LatexCommand cite
key "Nelson2020"
literal "false"

\end_inset

.
 Essentially, it is similar to the sine time series problem above, except
 that the periodic signal can be asymmetric due to ellipticity, giving 5
 parameters per planet (signal amplitude, period, pericenter time, eccentricity
 and mean anomaly) that describe a Keplerian orbit.
 Additionally, the white noise amplitude 
\begin_inset Formula $\sigma_{j}$
\end_inset

 and the systematic velocity 
\begin_inset Formula $C$
\end_inset

 are free parameters, giving 
\begin_inset Formula $2+N_{\mathrm{planets}}\times5$
\end_inset

 free parameters for 
\begin_inset Formula $N_{\mathrm{planets}}=0,1,2,3$
\end_inset

.
\end_layout

\begin_layout Subsection
Cosmology with the Cosmic Microwave Background
\end_layout

\begin_layout Standard
The Cosmic Microwave Background (CMB) is the oldest electromagnetic signal
 observable.
 It originated when the Universe underwent a transition from being so dense
 that photons would be constantly scattered to the current state where photons
 can travel freely.
 These photons allow us to measure the temperature of their regions of origin
 approximately 379,000 years after the Big Bang.
 A map of their emission over the sky gives information about the temperature
 correlation.
 This carries information of how the Big Bang inflation proceeded, which
 is dependent on important constituents of the Universe, such as the baryonic
 matter and dark matter content of the Universe.
 The CMB remains one of the most important experiments to measure cosmological
 parameters in the dark energy and cold dark matter cosmology framework
 (
\begin_inset Formula $\Lambda$
\end_inset

CDM).
 One difficulty in the fitting of cosmological models like 
\begin_inset Formula $\Lambda$
\end_inset

CDM to the CMB is that the prediction of angular correlations is computationally
 expensive (of the order of a few seconds per likelihood evaluation).
\end_layout

\begin_layout Standard
Here we adopt a tutorial example of the MontePython cosmology fitting package.
 We use the fake_planck_bluebook likelihood which emulates a Planck measurement.
 The free parameters are 
\begin_inset Formula $\Lambda$
\end_inset

CDM cosmological parameters, namely the baryonic density 
\begin_inset Formula $\Omega_{\mathrm{b}}$
\end_inset

, the dark matter density 
\begin_inset Formula $\Omega_{\mathrm{cdm}}$
\end_inset

, the scalar spectral index 
\begin_inset Formula $n_{s}$
\end_inset

, 
\begin_inset Formula $A_{s}$
\end_inset

, the hubble parameter value, relative to 
\begin_inset Formula $100\,\mathrm{km/s/Mpc}$
\end_inset

, 
\begin_inset Formula $h$
\end_inset

, and the time of reionisation 
\begin_inset Formula $\tau_{\mathrm{reion}}$
\end_inset

.
\end_layout

\begin_layout Subsection
X-ray spectral analysis of Active Galactic Nuclei
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/bixrayspectrum-30.pdf
	width 100col%

\end_inset


\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/bixrayspectrum-30_bending.pdf
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:xraydata"

\end_inset

X-ray spectra simultaneously fitted.
 
\emph on
Left
\emph default
 
\emph on
panel
\emph default
: Low-energy spectrum.
 The model (blue curve) is a sum of two powerlaws, one altered by a exponential
 truncation towards the low-energy side.
 That model is multiplied by the instrument sensitivty (gray curve), and
 background contamination (orange) is added.
 The final model is shown in green, from which poisson data are drawn (red
 crosses).
 
\emph on
Right
\emph default
 
\emph on
panel
\emph default
: High-energy spectrum.
 The intrinsic model is the same powerlaw, with a smooth powerlaw turnover
 (blue).
 The instrument sensitivity (gray) leads to an effective model (orange),
 from which poisson data (green crosses) are sampled.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Active Galactic Nuclei (AGN) are regions in the centres of massive galaxies
 where super-massive black holes grow.
 As gas swirls into the black hole, enormous amounts of radiation are produced
 by release of gravitational energy, sometimes shining brighter than all
 host galaxy stars together.
 Close to the black hole, X-rays are also produced and are an important
 tracer of the mass inflow into the black hole.
 They also allow identifying AGN in the sky, even when the black hole is
 surrounded by thick gas and dust, as most of the energetic X-rays penetrate
 through any obscurers.
 X-ray focusing instruments on-board satellites allow measurements of the
 X-ray spectra, which carry information on the AGN luminosity (and thus
 black hole mass accretion rate), obscuring column density and properties
 of the X-ray emitter (photon index, energy turn-over).
 The detection of X-ray radiation is performed by counting photon events
 and capturing an estimate of their energy, time of arrival and location
 on the sky.
 However, the energy response and energy-dependent sensitivity of the instrument
 adds some analysis complexity.
 Additionally, when few counts are detected, as is commonly the case, the
 process needs to be modelled with a Poisson likelihood.
\end_layout

\begin_layout Standard
Here, we present a example which emulates problems commonly encountered
 in X-ray analyses.
 The emission spectrum at low energies can be described as:
\begin_inset Formula 
\[
F=B+A_{LE}\times E^{-\Gamma}\times\left[\exp\left(-N_{\mathrm{H}}\times E^{-3}\right)+f_{\mathrm{scat}}\right]
\]

\end_inset

with background amplitude 
\begin_inset Formula $B$
\end_inset

, signal amplitude 
\begin_inset Formula $A$
\end_inset

, spectral photon index 
\begin_inset Formula $\Gamma$
\end_inset

, obscuring column density 
\begin_inset Formula $N_{H}$
\end_inset

, and fraction of the powerlaw that escapes unobscured 
\begin_inset Formula $f_{\mathrm{scat}}$
\end_inset

.
 This model shows a degeneracy when 
\begin_inset Formula $A$
\end_inset

 is low and comparable to 
\begin_inset Formula $B$
\end_inset

, because high 
\begin_inset Formula $N_{H}$
\end_inset

 and high 
\begin_inset Formula $f_{\mathrm{scat}}$
\end_inset

 look like 
\begin_inset Formula $N_{H}=0$
\end_inset

 (a simple powerlaw).
 The full emission model is illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:xraydata"

\end_inset

.
 At high energies, a smooth break is included (blue curve in right panel).
 However, the signal is low-count, so that the width of the break, 
\begin_inset Formula $\Delta_{\mathrm{brk}}$
\end_inset

, is difficult to estimate.
 Additionally, the break location, 
\begin_inset Formula $E_{\mathrm{brk}}$
\end_inset

, and photon index above the break, 
\begin_inset Formula $\Gamma_{HE}$
\end_inset

, are degenerate.
 We define the priors as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log A & \sim & \mathrm{Uniform}(-5,+5)\\
\Gamma & \sim & \mathrm{Normal}(2,0.2^{2})\\
\text{\ensuremath{\log N_{\mathrm{H}}}} & \sim & \mathrm{Uniform}(-3,+3)\\
\log f_{\mathrm{scat}} & \sim & \mathrm{Uniform}(-7,-1)\\
\ln B & \sim & \mathrm{Normal}(0.2,0.1^{2})\\
\log A_{HE} & \sim & \mathrm{Normal}(\log A,0.5^{2})\\
\log E_{\mathrm{brk}} & \sim & \mathrm{Uniform}(1,3)\\
\log\Delta_{\mathrm{brk}} & \sim & \mathrm{Uniform}(-2,1)\\
\Gamma_{HE} & \sim & \mathrm{Uniform}(-5,5)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Gravitational wave analysis
\end_layout

\begin_layout Standard
Gravitational waves originate from distortions of space-time by compact
 objects.
 Recently, the development of multiple, extremely sensitive instruments
 have allowed the observation of two black holes merging [ref].
 The gravitational event GW170817 was the first event detected by three
 detectors and allowed for the first time localisation on the sky, albeit
 with substantial parameter degeneracies.
\end_layout

\begin_layout Standard
Here we adopt a tutorial example of the PyCBC Gravitational wave analysis
 package
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
based on 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/gwastro/PyCBC-Tutorials/blob/7f5ff8fdd40c5dce2237b6082e1755b4a
ba9b989/tutorial/inference_1_ModelsAndPEByHand.ipynb
\end_layout

\end_inset


\end_layout

\end_inset

.
 The merging system GW170817 is described by the mass ratio 
\begin_inset Formula $q$
\end_inset

, the chirp mass 
\begin_inset Formula $m_{\mathrm{chirp}}$
\end_inset

, which is a combination of the two masses that influences the signal amplitude,
 the inclination 
\begin_inset Formula $i$
\end_inset

 of the system relative to the observer, the time of coalescence 
\begin_inset Formula $t_{c}$
\end_inset

 in seconds, the distance 
\begin_inset Formula $d$
\end_inset

 and position on the sky (
\begin_inset Formula $RA$
\end_inset

, 
\begin_inset Formula $DEC$
\end_inset

).
 The priors adopted are:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
q & \sim & \mathrm{Uniform}(1,2)\\
m_{\mathrm{chirp}} & \sim & \mathrm{Uniform}(1,2)\\
\sin i & \sim & \mathrm{Uniform}(0,1)\\
t_{c}-t_{m} & \sim & \mathrm{Uniform}(0.02,0.05)\\
d & \sim & \mathrm{Uniform}(10,100)\\
RA & \sim & \mathrm{Uniform}(0,2\pi)\\
\cos DEC & \sim & \mathrm{Uniform}(-1,1)
\end{align*}

\end_inset

where 
\begin_inset Formula $t_{m}$
\end_inset

 is the time automatically associated by an automated pipeline searching
 for candidate events in the noise.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Subsection
Problem Space
\end_layout

\begin_layout Standard
Show problem space.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/evaluateproblems.pdf
	width 100text%
	BoundingBox 0bp 0bp 983bp 972bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Models"

\end_inset

Parameter space of the problems over the defined six characteristics.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Comparison of Samplers
\end_layout

\begin_layout Subsection
Monte Carlo Samplers
\end_layout

\begin_layout Standard
We compare open source Monte Carlo samplers
\end_layout

\begin_layout Itemize
Affine-invariant ensemble sampler (emcee)
\end_layout

\begin_layout Itemize
MCMC Slice ensemble sampler (zeus)
\end_layout

\begin_layout Itemize
Laplace approximation, Variational Bayes with Importance Sampler (snowline)
\end_layout

\begin_layout Itemize
Nested Sampling with Multi-Ellipsoidal sampling (nestle)
\end_layout

\begin_layout Itemize
Dynamic Nested Sampling with MCMC, multi-ellipsoidal and RadFriends, depending
 on the dimensionality (dynesty)
\end_layout

\begin_layout Itemize
Ensemble Nested Sampling with MLFriends (UltraNest)
\end_layout

\begin_layout Itemize
Ensemble Nested Sampling with auto-tuning HARM (UltraNest)
\end_layout

\begin_layout Subsection
Evaluation criteria
\end_layout

\begin_layout Standard
Quantitative Criteria for correctness evaluation: 
\end_layout

\begin_layout Itemize
in analytic problems, recover logZ to 0.3 + 
\begin_inset Formula $0.1\sqrt{d}$
\end_inset

 accurately
\end_layout

\begin_layout Itemize
in analytic problems, recover quantiles to 
\begin_inset Formula $\Delta qq<0.05$
\end_inset

 accuracy
\end_layout

\begin_layout Itemize
in non-analytic problems where Stan is feasible, recover quantiles to 
\begin_inset Formula $\Delta qq<0.25$
\end_inset

 accuracy
\end_layout

\begin_layout Itemize
in all problems: posterior includes input values
\end_layout

\begin_layout Standard
Quantitative Criteria for efficiency evaluation:
\end_layout

\begin_layout Itemize
Number of model evaluations until termination (equal number of effective
 samples are targeted)
\end_layout

\begin_layout Subsection
Results
\end_layout

\begin_layout Standard
For each method: Plot method posterior correctness over parameter space,
 use LinearSVM to smooth.
\end_layout

\begin_layout Standard
For each method: Plot method logZ correctness over parameter space, use
 LinearSVM to smooth.
\end_layout

\begin_layout Standard
Plot problem parameter space vs most efficient method.
 Use LinearSVM to smooth.
\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Section*
Acknowledgements
\end_layout

\begin_layout Standard
I thank Frederik Beaujean for insightful conversations.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "../../../../../PostDoc/literature/stats"
options "/home/user/Downloads/integration-problem-set/pres/spmpsci"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
appendix
\end_layout

\end_inset


\end_layout

\begin_layout Section
Mock problems
\begin_inset CommandInset label
LatexCommand label
name "sec:Mock-problems"

\end_inset


\end_layout

\begin_layout Subsection
Sine time series
\end_layout

\begin_layout Standard
Analyses of inhomogeneously sampled light curves is a common problem in
 astrophysics, sometimes with complex noise processes and semi-periodic
 signals.
 Here we present a simple multi-component sine signal as a toy problem,
 and uniformly randomly sample observing times.
 The problem is defined as:
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename sine.pdf
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Sine-data"

\end_inset

Sine time series data (orange) with generating two-component model.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log L & = & \prod_{i=1}^{M}\mathrm{Normal}(m(t_{i},\theta)-d_{i},\sigma^{2})\\
m(t,\theta) & = & m_{0}+\sum_{j=1}^{n_{\mathrm{comp}}}A_{c}\times\sin\left(\frac{2\pi t}{P_{j}}+\phi_{j}\right)\\
m_{0} & \sim & \mathrm{Uniform}(-50,50)\\
\log\sigma & \sim & \mathrm{Uniform}(-1.5,-0.5)\\
\log A & \sim & \mathrm{Uniform}(-2,2)\\
\phi & \sim & \mathrm{Uniform}(0,2\pi)\\
\log P & \sim & \mathrm{Uniform}(-1,3)
\end{align*}

\end_inset

Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Sine-data"

\end_inset

 presents a graph 
\begin_inset Formula $(t_{i},d_{i})$
\end_inset

 of 
\begin_inset Formula $M=40$
\end_inset

 data points, generated by sampling 
\begin_inset Formula $n_{\mathrm{comp}}=2$
\end_inset

 components with offset 
\begin_inset Formula $m_{0}=-5$
\end_inset

, measurement uncertainty 
\begin_inset Formula $\sigma=0.1$
\end_inset

, amplitudes 
\begin_inset Formula $A_{1}=0.25$
\end_inset

, 
\begin_inset Formula $A_{2}=0.05$
\end_inset

, periods 
\begin_inset Formula $P_{1}=180$
\end_inset

, 
\begin_inset Formula $P_{2}=44$
\end_inset

 and phases 
\begin_inset Formula $\phi_{1}=0$
\end_inset

, 
\begin_inset Formula $\phi_{2}=1\,\mathrm{rad}$
\end_inset

.
 The same data are analysed with 
\begin_inset Formula $n_{\mathrm{comp}}=0,\,1,\,2,\,3$
\end_inset

, producing two to eleven dimensional problems with completely exchangable
 components.
\end_layout

\begin_layout Subsection
Low X-ray count observations of a Compton-thick AGN
\end_layout

\begin_layout Standard
This mock problem describes a 5-dimensional degenerate physical parameter
 space discussed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Buchner2014"
literal "false"

\end_inset

.
 TODO
\end_layout

\begin_layout Section
Toy problems
\begin_inset CommandInset label
LatexCommand label
name "sec:Toy-problems"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "subsec:Toy-problems"

\end_inset


\end_layout

\begin_layout Standard
In this section, the prior is the unit hypercube (
\begin_inset Formula $0<\theta_{i}<1$
\end_inset

 for 
\begin_inset Formula $1\leq i\leq d$
\end_inset

), unless specified otherwise.
 If analytically known, the marginal parameter posterior distribution 
\begin_inset Formula $p(\theta_{i}|D)$
\end_inset

 and marginal likelihood 
\begin_inset Formula $Z$
\end_inset

 are given.
\end_layout

\begin_layout Subsection
Asymmetric Gaussian
\end_layout

\begin_layout Standard
Integration of a Gaussian distribution is a standard test problem.
 The variation here introduces some parameter inequality and spreads the
 means in a sine pattern, so that the posterior is not centred on the prior
 range.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
L & = & \prod_{i=1}^{d}\mathrm{Normal}(\mu_{i},\sigma_{i}^{2})\\
\sigma_{i} & = & 0.1\times10^{-\left(-9-\frac{\sqrt{d}}{2}\right)\times\frac{i-1}{d-1}}\\
\mu_{i} & = & \frac{1}{2}+\frac{1-5\sigma_{i}}{2}\times\sin\frac{i-1}{2d}
\end{align*}

\end_inset

This problem is evaluated using uniform priors on 
\begin_inset Formula $d=4$
\end_inset

 (making 
\begin_inset Formula $\sigma_{i}$
\end_inset

 range from 
\begin_inset Formula $10^{-9}$
\end_inset

 to 
\begin_inset Formula $10^{-1}$
\end_inset

), 
\begin_inset Formula $16$
\end_inset

 (
\begin_inset Formula $10^{-8}<\sigma_{i}<10^{-1}$
\end_inset

) and 
\begin_inset Formula $100$
\end_inset

 dimensions (
\begin_inset Formula $10^{-5}<\sigma_{i}<10^{-1}$
\end_inset

).
 The four-dimensional case is shown in the top left panel of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

.
 Note the different axes ranges.
 The true posterior is 
\begin_inset Formula $p(\theta_{i}|D)=\mathrm{Normal}(\mu_{i},\sigma_{i}^{2})$
\end_inset

, and the marginal likelihood 
\begin_inset Formula $Z\approx1$
\end_inset

.
\end_layout

\begin_layout Subsection
Correlated Funnel
\end_layout

\begin_layout Standard
Neil's funnel is a standard test problem that represents features of hierarchica
l Bayesian models.
 It is a normal distribution with the standard deviation also a free parameter.
 This causes a funnel shape (see middle panel of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

) involving all parameters.
 Such non-affine correlations can sometimes be eased significantly by reparametr
izations which scale the unknown mean parameters by the standard deviation
 parameter 
\begin_inset CommandInset citation
LatexCommand cite
key "Betancourt2013"
literal "false"

\end_inset

.
 Here we use the correlated version of 
\begin_inset CommandInset citation
LatexCommand cite
key "Karamanis2020"
literal "false"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
L & = & \prod_{i}\mathrm{Normal}(\mu_{i}-\gamma\times\mu_{i-1},\Sigma^{2})\\
\ln\sigma & \sim & \mathrm{Normal}(0,1)\\
\mu_{i} & \sim & \mathrm{Uniform}(-100,100)\\
\Sigma_{ij} & = & \begin{cases}
\sigma & \mathrm{if\,}i=j\\
\gamma\times\sigma & \mathrm{otherwise}
\end{cases}
\end{align*}

\end_inset

This problem is tested in 2, 10 and 50 dimensions with correlation strength
 
\begin_inset Formula $\gamma=0.95$
\end_inset

.
 The true marginal posteriors are 
\begin_inset Formula $p(\mu_{i}|D)=\mathrm{Normal}(0,1)$
\end_inset

, 
\begin_inset Formula $p(\ln\mu_{i}|D)=\mathrm{Normal}(0,1)$
\end_inset

, and the marginal likelihood 
\begin_inset Formula $Z\approx1$
\end_inset

.
\end_layout

\begin_layout Subsection
Rosenbrock function
\end_layout

\begin_layout Standard
The Rosenbrock function is a standard test problem in optimization.
 It exhibits a non-linear, narrow degeneracy that can be difficult to navigate
 (right middle panel of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

).
 We adopt a probabilistic formulation suggested by 
\begin_inset CommandInset citation
LatexCommand cite
key "RosenbrockChallenge"
literal "false"

\end_inset

 (see a similar version in 
\begin_inset CommandInset citation
LatexCommand cite
key "Jia2019"
literal "true"

\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log L & = & -2\times\sum_{i=1}^{d-1}100\times\left(\theta_{i+1}-x_{i}^{2}\right)^{2}+\left(1-\theta_{i}\right)^{2}\\
\theta_{i} & \sim & \mathrm{Uniform}(-10,10)
\end{align*}

\end_inset

We test this problem in 2, 20 and 50 dimensions.
\end_layout

\begin_layout Subsection
Eggbox
\end_layout

\begin_layout Standard
The eggbox function is a two-dimensional extremely multi-modal function
 (bottom left panel of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

) proposed by 
\begin_inset CommandInset citation
LatexCommand cite
key "Feroz2008"
literal "false"

\end_inset

, defined as: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log L & = & \left(2+\cos(5\pi\cdot\theta_{1})\cdot\cos(5\pi\cdot\theta_{2})\right)^{5}\\
\theta_{i} & \sim & \mathrm{Uniform}(0,10\pi)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Beta product
\end_layout

\begin_layout Standard
Diverse test problems can be generated by combining standard one-dimensional
 probability distributions.
 Here, the Beta distribution is used to represent diverse posterior shapes
 in each parameter:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
L & = & \prod_{i=1}^{d}\mathrm{Beta}(a_{i},b_{i})
\end{align*}

\end_inset

with fixed, known 
\begin_inset Formula $a$
\end_inset

,
\begin_inset Formula $b$
\end_inset

, randomly generated as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log a_{i} & \sim & \mathrm{Uniform}(-1,1)\\
\log b_{i} & \sim & \mathrm{Uniform}(-1,1)
\end{align*}

\end_inset

This distribution can produce multiple modes (where 
\begin_inset Formula $a_{i}<1$
\end_inset

 and 
\begin_inset Formula $b_{i}<1$
\end_inset

), non-Gaussian tails.
 The likelihood is relatively uninformative on each parameter (completely
 non-informative when 
\begin_inset Formula $a_{i}=b_{i}=0$
\end_inset

).
 We test this problem in 2, 10 and 30 dimensions.
 The true marginal posteriors are given by 
\begin_inset Formula $P(\theta_{i}|D)=\mathrm{Beta}(a_{i},b_{i})$
\end_inset

, and the marginal likelihood is 
\begin_inset Formula $Z=1$
\end_inset

.
\end_layout

\begin_layout Subsection
LogGamma
\end_layout

\begin_layout Standard
The LogGamma problem 
\begin_inset CommandInset citation
LatexCommand cite
key "Beaujean2013"
literal "false"

\end_inset

 exhibits multi-modality and heavy tails, which lead to non-elliptical contours.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
g_{a} & \sim & \mathrm{LogGamma}\left(1,\,\frac{1}{3},\,\frac{1}{30}\right)\\
g_{b} & \sim & \mathrm{LogGamma}\left(1,\,\frac{2}{3},\,\frac{1}{30}\right)\\
n_{c} & \sim & \mathrm{Normal}\left(\frac{1}{3},\,\frac{1}{30}\right)\\
n_{d} & \sim & \mathrm{Normal}\left(\frac{2}{3},\,\frac{1}{30}\right)\\
d_{i} & \sim & \mathrm{LogGamma}\left(1,\,\frac{2}{3},\,\frac{1}{30}\right)\,\text{\,\,\ if\,\,\,}3\leq i\leq\frac{d+2}{2}\\
d_{i} & \sim & \mathrm{Normal}\left(\frac{2}{3},\,\frac{1}{30}\right)\,\text{\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\ if\,\,\,}\frac{d+2}{2}<i\\
L_{1} & = & \frac{1}{2}\left(g_{a}(x_{1})+g_{b}(x_{1})\right)\\
L_{2} & = & \frac{1}{2}\left(n_{c}(x_{2})+n_{d}(x_{2})\right)\\
L & = & L_{1}\times L_{2}\times\prod_{i=3}^{d}d_{i}(x_{i})
\end{eqnarray*}

\end_inset

We test this problem in 2, 10 and 30 dimensions.
 The true marginal posteriors are given by 
\begin_inset Formula $P(x_{1}|D)=L_{1}(x_{1})$
\end_inset

, and the marginal likelihood is 
\begin_inset Formula $Z=1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsubsection
AR(1) process
\end_layout

\begin_layout Plain Layout
A first-order auto-regressive process (AR(1)) can be used as a test problem
 of correlated parameters:
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{align*}
L & = & \mathrm{Normal}(x_{1},1)\prod_{i=1}^{d-1}\mathrm{Normal}(\mu_{i+1}-\alpha\mu_{i},\beta^{2})\\
\alpha & = & 0.95\\
\beta & = & \sqrt{1-\alpha^{2}}
\end{align*}

\end_inset

We test this problem in 2, 10 and 25 dimensions.
\end_layout

\end_inset


\end_layout

\end_body
\end_document
