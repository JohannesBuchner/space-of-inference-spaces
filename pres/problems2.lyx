#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass aa
\begin_preamble
\titlerunning{A space of parameter spaces in the space sciences}
\end_preamble
\options twocolumn
\use_default_options true
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\pdf_quoted_options "unicode=true"
\papersize a4paper
\use_geometry false
\use_package amsmath 2
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\rightmargin 5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
A space of parameter spaces in the space sciences: parametric Bayesian inference
 in astronomy, cosmology and particle physics
\end_layout

\begin_layout Abstract (unstructured)
A sample of parametric Bayesian inference applications from astronomy, cosmology
 and particle physics is studied, augmented by mock data sets and toy problems.
 The parameter spaces and posterior distributions are characterized by (1)
 the number of model parameters, (2) whether the posterior shape is similar
 to a gaussian, (3) whether the posterior has light or heavy tails, (4)
 how small the posterior is compared to the prior, i.e., how informative the
 data are, (5) whether some parameters remain unconstrained while others
 are highly constrained, (6) whether the posterior has multiple, disconnected
 modes.
 These axis define a parameter space of inference problems.
 We characterize each of the inference problems and observe that inference
 in astrophysics spans the entire parameter space, from low to high dimensionali
ty, mono- to multi-modal, and a variety of complex distributions that range
 from uninformative to highly informative.
 Furthermore, the computational cost of the physical models can range from
 milliseconds to dozens of seconds.
 The collated sample of inference problems is proposed as a standard test
 bed for new samplers.
 For reproducibility and ease of use, a Docker compute image is provided.
\end_layout

\begin_layout Author
Johannes Buchner
\end_layout

\begin_layout Address
Max Planck Institute for Extraterrestrial Physics, Giessenbachstrasse, 85741
 Garching, Germany
\end_layout

\begin_layout Keywords
Bayesian inference; parametric models; astrophysics
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Fitting parametric models to experimental data is one of the key methods
 to infer physical parameters.
 In physics, investigation of distant processes is possible by modelling
 the measurement process accurately.
 Here, we focus on problems where the model has continuous parameters with
 predefined prior ranges, and where a likelihood function has been defined
 to compare the model prediction to data.
 Some examples include fitting the power spectrum of the Cosmic Microwave
 Background (CMB) with Dark Energy and Cold Dark Matter (
\begin_inset Formula $\lambda$
\end_inset

CDM) cosmologies, fitting time series of the radial velocity of a host star
 gravitationally pulled by its exoplanets, dissecting multiple components
 in spectra and population inference from uncertain measurements of many
 individual objects, such as luminosity or mass functions.
 The plausible ranges of model parameters that match the data are typically
 tested in a Bayesian framework once prior and likelihood are specified
 with Monte Carlo samplers.
\end_layout

\begin_layout Standard
Monte Carlo sampling methods of varying complexity have been developed over
 the last decades.
 This includes variations of Markov Chain Monte Carlo (MCMC), Particle Monte
 Carlo (PMC), Importance Samplers (IS) and Nested Samplers (NS).
 Specific implementations specify the initialisation, exploration strategy
 (e.g., proposal function) and termination criterion.
 These are often tuned for the application.
 Reliable parameter recovery of a method can be tested by Monte Carlo simulating
 new datasets, and analysing them.
 An alternative are toy inference problems that approximate features of
 the real problem.
 These can be more easily understood and more rapidly analysed.
 Given the diversity of algorithms and inference problems, it is interesting
 to consider whether a different algorithm can perform well on the same
 problem, and whether the currently used algorithm can be transferred to
 another problem.
 This work is focusing on the applicability of Monte Carlo Samplers over
 different types of inference problems.
\end_layout

\begin_layout Standard
Inference problems differ substantially by the posterior distribution that
 a Monte Carlo sampler has to explore.
 The main characteristics of problems include (1) the number of model parameters
, (2) whether the posterior shape is similar to a gaussian, (3) whether
 the posterior has light or heavy tails, (4) how small the posterior is
 compared to the prior (i.e., how informative the data are), (5) whether some
 parameters remain unconstrained while others are highly constrained, (6)
 whether the posterior has multiple, disconnected peaks.
 Besides a systematic classification of inference problems based on five
 characteristics, this work presents a diverse set of real and toy inference
 problems that cover the entire classification space.
\end_layout

\begin_layout Section
Data: collated inference problems
\end_layout

\begin_layout Standard
To cover most of the problem space, we collected inference problems published
 in the literature and available in open-source physics packages.
 Appendix
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Real-problems"

\end_inset

 introduces real-world problems, which form the main sample in this work.
 Simplified mock problems with generated data sets that approximate real-world
 problems are presented in Appendix
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Mock-problems"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Appendix
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Toy-problems"

\end_inset

 introduces artificial toy problems.
 
\end_layout

\begin_layout Standard
For each problem, the likelihood function 
\begin_inset Formula $L(\theta)$
\end_inset

 is defined together with prior distribution 
\begin_inset Formula $\pi(\theta)$
\end_inset

 over the parameter space.
 
\end_layout

\begin_layout Section
Method: Characterization of parametric inference
\end_layout

\begin_layout Standard
Various difficulties are encountered by different sub-disciplines.
 Here we specify six characteristics and give a mathematical definition
 for each.
 Finally, we present a visual presentation which characterizes the posterior
 degeneracies.
\end_layout

\begin_layout Subsection
Dimensionality
\end_layout

\begin_layout Standard
In astrophysics, fitting problem dimensionalities range from 1 to millions
 parameters.
 Examples of extremely high-dimensional problems include pixel reconstructions
 (e.g., ) and .
 With more parameters, the possible combinations of parameter values rises
 exponentially (the curse of dimensionality).
 This makes the problem complex to explore and distances between parameter
 space points meaningless.
 
\end_layout

\begin_layout Standard
Here we defined three common sub-groups: low-dimensional (
\begin_inset Formula $d=2-9$
\end_inset

), mid-dimensional (
\begin_inset Formula $d=10-29$
\end_inset

) and high-dimension (
\begin_inset Formula $d\geq30$
\end_inset

).
 The boundaries are set near where simple and more sophisticated ideas of
 geometric sampling start failing.
 Extremely high dimensions (
\begin_inset Formula $d\gg100$
\end_inset

) are not the focus of this work.
 We note that these virtually always require the derivatives of likelihood
 functions to effectively navigate the parameter space.
 The availability of likelihood derivatives could be considered an additional
 classification category.
\end_layout

\begin_layout Subsection
Information gain
\end_layout

\begin_layout Standard
Depending on the data quality of the experiment, the posterior may be a
 tiny region of the prior, or be identical with the prior.
 This can be quantified by the Kullback-Leibler divergence, or surprise,
 between the two probability distributions:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
D_{\mathrm{KL}}=\int\pi(\theta)\ln\frac{\pi(\theta)}{P(\theta)}d\theta
\]

\end_inset

Here, 
\begin_inset Formula $\pi$
\end_inset

 and 
\begin_inset Formula $P$
\end_inset

 give the prior and posterior over the parameter vector space 
\begin_inset Formula $\theta$
\end_inset

.
 In the case of a base-e logarithm, the unit of 
\begin_inset Formula $D_{\mathrm{KL}}$
\end_inset

is nats, and approximately means how many e-foldings it takes to cut the
 prior until the posterior is reached.
 Finding that small region can be a challenge for sampling algorithms (and
 maximum likelihood minimizers).
\end_layout

\begin_layout Standard
In practice, the information gain is already computed by nested sampling
 algorithms internally for error estimation, and we adopt that method as
 a measurement.
 Also, the information gain is related to the number of iterations of the
 nested sampling algorithms needs to zoom in until the likelihood appears
 flat.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\align center

\size footnotesize
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
input{../paramspacefigs.tex}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:pairwise-posterior"

\end_inset

Selected pair-wise posterior distributions from some of our problems.
 The 1, 2, 3 and 4-sigma equivalent probability mass contours 
\begin_inset CommandInset citation
LatexCommand citep
before "made with corner;"
key "Foreman-Mackey2016"
literal "false"

\end_inset

 illustrate non-linear degeneracies (e.g., middle panels), unequal axes (e.g.,
 left-most and right-most top panels), multi-modality (bottom panels).
 The loggamma problem (third panel, bottom row) also has heavy tails towards
 the left.
 Some parameters are uninformative (e.g., param1 in top right panel) or at
 the prior parameter edge (middle left panel, ratio 
\begin_inset Formula $q\geq1$
\end_inset

, top right panel, 
\begin_inset Formula $0\leq\mathrm{param2}\leq1$
\end_inset

).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Multi-modality
\end_layout

\begin_layout Standard
When data can be explained with similar quality by different combinations
 of processes, the posterior exhibits multiple peaks.
 This is common in fits of multiple components with (nearly-)interchangable
 predictions, paired with poor descrimination power of the data.
 Algorithms based on local jumps can find it difficult to navigate between
 modes, because a proposal tuned to a single mode may reach another distant
 mode with vanishing proposal probability.
 The bottom row of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

 shows examples of multimodal distributions.
\end_layout

\begin_layout Standard
To mathematically define multi-modality, a threshold criterion is needed
 to define disconnectedness.
 In principle any clustering algorithm can be used.
 For simplicity and reproducibility, we adopt a simple approach.
 First, histograms of the marginal posteriors are histogrammed into 20 bins.
 Bins with density less than 1/5 of the peak density are considered 
\begin_inset Quotes eld
\end_inset

empty
\begin_inset Quotes erd
\end_inset

.
 Gaps are identified, and thresholds that bracket the peaks extracted.
 This is repeated for every dimension.
 Then, all combinations of brackets are computed.
 These are the clusters.
 If posterior samples are members of multiple clusters, the clusters are
 merged.
 The number of remaining, non-empty clusters is the number of modes of the
 problem.
\end_layout

\begin_layout Subsection
Non-Gaussianity
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/evaluateproblems_volcurve.pdf
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:volcurve"

\end_inset

Probability fraction enclosed as a function of prior volume.
 From the highest likelihood regions outwards, the volume is increased from
 left to right until the entire prior space (
\begin_inset Formula $V=1$
\end_inset

) is enclosed.
 The median (cross) indicates how large the posterior volume is relative
 to the prior, and is related to the 
\emph on
information gain
\emph default
.
 Quantiles at 5% and 95% indicated as circles indicate the shell where most
 probability mass is enclosed.
 This is related to the 
\emph on
tail weight
\emph default
.
 Some problems show wide transitions (e.g., green dashed) relative to a gaussian
 (blue dashed).
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The Bernstein–von Mises theorem states that when the data are highly informative
, the posterior is shaped like a multi-variate Gaussian.
 Then, Laplace's approximation of the posterior with a log-quadratic density
 function is justified.
 This can furthermore occur if the model is linear in its parameters, or
 a first-order Taylor expansion of the model provides a reasonable approximation
 at the maximum a posteriori.
 For this reason, some algorithms are constructed to behave optimally when
 the posterior is Gaussian (see e.g., Laplace approximation).
\end_layout

\begin_layout Standard
The Gaussianity of a posterior can be easily measured through the surprise
 from a best-fitting multi-variate Gaussian to the posterior.
 We obtain a suitable gaussian from the mean and covariance of the posterior
 samples.
 In multi-modal cases, the posterior is highly non-gaussian.
\end_layout

\begin_layout Subsection
Tail weight
\end_layout

\begin_layout Standard
While the posterior may have ellipsoidal contours like a Gaussian, the posterior
 density may decline steeper or shallower than a square-exponential, i.e.,
 have thin or heavy tails.
 For example, when outliers are allowed (e.g., in student-t distribution or
 explicit outlier modelling), the wings of the posterior can be wide.
 Some algorithms may be optimized for square-exponential declines.
 Another cause of heavy tails is when most data points are fitted well by
 one component, and a minor component relevant for a small data subset improves
 the fit slightly (for example, in blind spectral line searches on top of
 a continuum).
 This leads to a phase transition, where the parameter space to be explored
 changes rapidly (with small likelihood change) from a wide volume to a
 narrow volume.
 This is difficult for many samplers.
\end_layout

\begin_layout Standard
To quantify how the weight is distributed over the prior volume, we compute
 the prior volume above a given likelihood threshold.
 This is illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:volcurve"

\end_inset

.
 We compute the 
\begin_inset Formula $5\%$
\end_inset

 and 
\begin_inset Formula $95\%$
\end_inset

 quantiles of the volume ranges where most of the probability mass resides,
 and compute the tail weight as:
\begin_inset Formula 
\[
\mathrm{TW}=\log\frac{V_{5\%}}{V_{95\%}}
\]

\end_inset

In practice, the mapping of volume and likelihood, as well as the normalising
 constant, the marginal likelihood integrated over volume shrinkages, is
 already computed internally in nested sampling.
 We cap the value at 
\begin_inset Formula $\mathrm{TW}=\log10\times d$
\end_inset

.
\end_layout

\begin_layout Subsection
Parameter Inequality
\end_layout

\begin_layout Standard
Some model parameters may alter the model prediction strongly, while others
 have more minute implications.
 Because of this, the posterior of some parameters can be consistent with
 the prior with no information learnt.
 For other parameters, its plausible range may have diminished by several
 orders of magnitude.
 Proposals that are isotropic over the parameter space directions then may
 perform poorly.
 The top row of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

 shows such examples in pairs of parameters.
 
\end_layout

\begin_layout Standard
We quantify the inequality of parameters in problems by marginal posterior
 standard deviations 
\begin_inset Formula $\sigma_{i}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathrm{IE}=\log\frac{\max\sigma_{i}}{\min\sigma_{i}}
\]

\end_inset

If all parameters have similar posterior uncertainties, 
\begin_inset Formula $\mathrm{IE}\approx0$
\end_inset

.
 We cap this value to at most 
\begin_inset Formula $\mathrm{IE}=10$
\end_inset

.
\end_layout

\begin_layout Subsection
Compact visualisation of posterior structure
\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "subsec:Compact-visualisation-of"

\end_inset


\end_layout

\begin_layout Standard
For a visual impression of the experienced parameter space and its linear
 and non-linear degeneracies, a common tool are corner plots.
 These are also known in the statistics literature as pairs plots, and an
 example is shown in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:corner-example-1"

\end_inset

.
 Here, we quantify the further interaction between pairs of parameters and
 present a compact visualisation as a 
\begin_inset Formula $d\times d$
\end_inset

 matrix.
 The diagonal entries are filled with the information gain 
\begin_inset Formula $H$
\end_inset

 expressed in bits.
 The upper and lower triangles are populated with correlation coefficients
 of pairs of parameters.
\end_layout

\begin_layout Standard
Corner plots only consider the posterior distribution.
 However, to express the experience of a sampler fairly, the characterization
 should consider also the prior.
 Here we work with the posterior samples expressed with coordinates on the
 prior cumulative probability distribution (probability integral transform).
 In the case of nested samplers working with prior transforms based on the
 unit hyper-cube, this merely means we take the un-transformed posterior
 samples.
 First, we characterize the linear degeneracies.
 the pair-wise Pearson correlation coefficient 
\begin_inset Formula $\rho_{\mathrm{Pearson}}$
\end_inset

 is calculated for each posterior parameter pair.
 Secondly, we characterize residual non-linear degeneracies.
 We apply an affine transform which standardizes the parameter space to
 be linearly independent, and then compute the pair-wise Spearman correlation
 coefficient 
\begin_inset Formula $\rho_{\mathrm{Spearman}}$
\end_inset

.
\end_layout

\begin_layout Standard
The obtained matrix visualisation is demonstrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:degeneracy-viz-example"

\end_inset

, corresponding to the corner plot in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:corner-example-1"

\end_inset

.
 The diagonal shows the parameter information gain, the lower triangle indicates
 the linear degeneracies and the upper triangle indicates the non-linear
 degeneracies.
 In the case of a un-correlated gaussian, illustrated in the right panel
 of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:degeneracy-viz-example"

\end_inset

, the off-diagonal elements are zero.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/exoplanet-rvs_0005.txt-1/ultranest-safe/simplified_posterior.pdf
	width 100text%
	BoundingBox 0bp 0bp 1120bp 1136bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:corner-example-1"

\end_inset

Corner plot 
\begin_inset CommandInset citation
LatexCommand citep
before "created with corner.py;"
key "Foreman-Mackey2016"
literal "false"

\end_inset

 for the exo-rv problem with 1 planet.
 The degeneracies can be non-linear (see e.g., ecc_p1 and K-p1).
 Some parameters are uninformative (omega_p1), while others are very well
 constrained.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/exoplanet-rvs_0005.txt-1/ultranest-safe/correlations.pdf
	width 80col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:degeneracy-viz-example"

\end_inset

Proposed visualisation of the degeneracies, corresponding to Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:corner-example-1"

\end_inset

.
 The lower left triangle in blue shows linear correlation between parameter
 posteriors (
\begin_inset Formula $|\rho_{\mathrm{Pearson}}|$
\end_inset

 from 0 to 1), with darker color indicating stronger correlation.
 Similarly, the upper right traingle in orange shows Spearman rank correlation
 between parameter posteriors, after removing the linear correlations.
 The diagonal entries in green indicate the information gain on the parameter,
 increasing from white to darker colors.
 Here, some parameters are uninformative while others are highly informative.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/asymgauss-16d/ultranest-fast-fixed4d/correlations.pdf
	width 80col%
	BoundingBox 0bp 0bp 299bp 297bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Same as Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:degeneracy-viz-example"

\end_inset

, but for our 16 dimensional Gaussian toy problem.
 Here, the non-diagonal entries are near zero, indicating (correctly) that
 there are no parameter degeneracies.
 The diagonal elements vary, with the first parameter being much less informativ
e than the others.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide true
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
input{../evaluateproblems.tex}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:List-of-problems"

\end_inset

List of problems analysed.
 The columns describe (1) research field, (2) name, (3) dimensionality,
 (4) model evaluation cost in milliseconds, (5) information gain, (6) tail
 weight, (7) parameter inequality, (8) Gaussian approximation information
 loss, (9) phase transition.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/evaluateproblems.pdf
	width 100line%
	BoundingBox 0bp 0bp 1045bp 1001bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Models"

\end_inset

Parameter space of the problems over the defined six characteristics.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/cmb-cosmology/ultranest-safe/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/ligo/ultranest-fast-fixed4d/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/icecube/ultranest-safe/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/crab/ultranest/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/transit/ultranest-safe/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/exoplanet-rvs_0005.txt-2/ultranest-fast-fixed4d/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/mosfit-LSQ12dlf/ultranest/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/mosfit-LSQ12dlf-magnetar/ultranest/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/xrayagnspec/ultranest-safe/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/line/ultranest-safe/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/posteriorstacker/posteriorstacker-gauss/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/systematiclogs/posteriorstacker/posteriorstacker-flex11/correlations.pdf
	width 50col%
	BoundingBox 0bp 0bp 294bp 297bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Posterior-structure-visualisatio"

\end_inset

Posterior structure visualisations (see section
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Compact-visualisation-of"

\end_inset

) for our real physics inference problems.
 The number of entries indicates the dimensionality, diagonal entries indicate
 parameter information gain, the bottom left triangle entries indicate linear
 parameter degeneracies and the upper right triangle indicates non-linear
 degeneracies.
 For example, the top left panel shows no non-linear degeneracy, while the
 bottom left panel shows strong non-linear degeneracies.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /mnt/data/daten/PostDoc2/research/stats/space-of-inference-spaces/evaluateproblems_spacestructure.pdf
	width 100col%
	BoundingBox 0bp 0bp 391bp 442bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:corr"

\end_inset

For each problem, the evolution of the Pearson correlation coefficient (x-axis)
 and the Spearman correlation coefficient as nested sampling raises the
 likelihood threshold is shown as a curve.
 Low coefficients (bottom left corner) indicate independent parameters,
 high x-axis values indicate strong linear degeneracies.
 High y-axis values indicate strong non-linear degeneracies, such as multiple
 modes, or bananas in the parameter space.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The collated problems are listed in Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "tab:List-of-problems"

\end_inset

, together with the derived characteristics.
 The model evaluation cost is also listed, and ranges from less than 1ms
 to almost 1s per likelihood evaluations.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Models"

\end_inset

 presents the location of each inference problem in a corner plot.
 Among the 
\begin_inset Quotes eld
\end_inset

real
\begin_inset Quotes erd
\end_inset

 physics inference problems (solid circles), there does not appear to a
 trend or preferred region of the parameter space; all regions are covered.
 The mock problems (crosses) cover the full parameter space as well.
\end_layout

\begin_layout Standard
The exoplanet radial velocity fitting with one planet appears to show a
 phase transition, and heavy-tailed posteriors.
 These properties are also produced by the spike and slab toy problem variations.
 Fitting for 3 exoplanets yield 9 modes, and the LSQ12dlf analyses show
 a similar number of modes.
 The multisine mock problem mimicks the properties of the exoplanet radial
 velocity fitting in terms of multi-modality, width, parameter asymmetry,
 phase transition and heavy-tailed posteriors, suggesting it is a useful
 approximation.
\end_layout

\begin_layout Standard
As already shown in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:volcurve"

\end_inset

, the information gain differs substantially.
 Additionally, the 
\begin_inset Quotes eld
\end_inset

asym
\begin_inset Quotes erd
\end_inset

 column of Table
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "tab:List-of-problems"

\end_inset

 indicates how much some parameters are learned while others are uninformative.
 This parameter can be very high (>30).
\end_layout

\begin_layout Standard
Beyond those summary statistics, Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Posterior-structure-visualisatio"

\end_inset

 presents a visual impression of the posterior structure.
 Based on the visualisation developed in section
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Compact-visualisation-of"

\end_inset

, this presents a diversity in dimensionality, as indicated by the number
 of entries, the parameter information gain (diagonal entries), the linear
 parameter degeneracies (bottom left triangles) and non-linear degeneracies
 (upper right entries).
 Some inference problems, such as cmb-planck (top left panel) show no non-linear
 degeneracy, while others (agn-xray-spectrum, bottom left panel) show strong
 non-linear degeneracies.
\end_layout

\begin_layout Standard
Finally, we have a deeper look at the evolving likelihood surface as the
 sampler moves from the prior to the posterior mass.
 To this end, we observe the live point distribution at regular snapshots.
 We apply the same procedure as in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Compact-visualisation-of"

\end_inset

 and note the largest Pearson and (linearly whitened) Spearman correlation
 coefficient.
 Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:corr"

\end_inset

 shows the evolution of these values for each inference problem.
 For problems with no parameter interactions, such as the asymgauss or beta,
 the curves remain in the bottom left corner of the plot.
 Other problems however show strong linear (Pearson) and/or non-linear (whitened
 Spearman) degeneracies over the parameter space.
 This behaviour is stronger for real problems (dashed and solid curves)
 than toy problems (dotted curves).
\end_layout

\begin_layout Section
Discussion & future work
\end_layout

\begin_layout Subsection
Strengths and limitations of the collected inference problems
\end_layout

\begin_layout Standard
This work has assembled a list of parametric Bayesian inference applications
 from astronomy, cosmology and particle physics.
 This is augmented by mock applications and toy problems.
 The parameter spaces and posterior distributions have been characterized
 and cast into a space of parametric inference spaces.
 
\end_layout

\begin_layout Standard
A major result of this work is that the parameter space structure of these
 inference spaces is highly diverse.
 They span from low to high dimensionality, can be mono-, bi- or multi-modal.
 A variety of complex posterior distribution morphologies appear, and inference
 on the parameters ranges from uninformative to extremely informative.
 Furthermore, the computational cost of the physical models can range from
 milliseconds to seconds.
\end_layout

\begin_layout Standard
To test samplers in realistic, but controlled conditions with known posteriors
 and evidence, toy inference problems are commonly used.
 Standard ones include a Gaussian, Neal's funnel, log-gamma, eggbox, rosenbrock
 and spike+slab, which are also included here.
 However, toy inference problems may not represent the experience of a sampler
 exploring the parameter space of a real data analysis problem.
 In particular, Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:corr"

\end_inset

 demonstrates that real inference problems can have stronger degeneracies
 than toy problems.
 There is more work to be done to create toy inference problems that closely
 mimick real physics inference.
 In this vain, we provide several small data sets which are easy to work
 with yet represent real physics data analysis (e.g., multisine, compton-thick-AGN
, sample-dist, powerlaw-relation, lennard-jones).
 In the future, perhaps the more complex data analysis pipelines can be
 replaced by auxiliary functions, for example based on Gaussian mixtures
 or normalising flows, which closely approximate the real likelihood function,
 but have known, analytic properties (integral Z, marginal distributions).
 Despite the limitations of artificial toy problems, Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Models"

\end_inset

 demonstrates that these cover the same (vast) parameter space as the real
 inference problems (compare the filled circles to crosses).
\end_layout

\begin_layout Subsection
Performance of samplers
\end_layout

\begin_layout Standard
In recent years, a variety of Bayesian inference sampling packages have
 been published.
 MCMC-based algorithms include emcee 
\begin_inset CommandInset citation
LatexCommand citep
key "Foreman-Mackey2013"
literal "false"

\end_inset

, Stan 
\begin_inset CommandInset citation
LatexCommand citep
key "Carpenter2017"
literal "false"

\end_inset

, zeus 
\begin_inset CommandInset citation
LatexCommand citep
key "Karamanis2020"
literal "false"

\end_inset

 and pocoMC 
\begin_inset CommandInset citation
LatexCommand citep
key "Karamanis2022"
literal "false"

\end_inset

.
 Nested sampling-based algorithms include multinest 
\begin_inset CommandInset citation
LatexCommand citep
key "Feroz2009"
literal "false"

\end_inset

, polychord 
\begin_inset CommandInset citation
LatexCommand citep
key "Handley2015a"
literal "false"

\end_inset

, DNest4 
\begin_inset CommandInset citation
LatexCommand citep
key "Brewer2018DNest4"
literal "false"

\end_inset

, dynesty 
\begin_inset CommandInset citation
LatexCommand citep
key "Speagle2020"
literal "false"

\end_inset

, ultranest 
\begin_inset CommandInset citation
LatexCommand citep
key "UltraNest"
literal "false"

\end_inset

, nautilus 
\begin_inset CommandInset citation
LatexCommand citep
key "Lange2023"
literal "false"

\end_inset

 and i-nessai 
\begin_inset CommandInset citation
LatexCommand citep
key "Williams2023"
literal "false"

\end_inset

.
 For reference snowline
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://johannesbuchner.github.io/snowline/
\end_layout

\end_inset


\end_layout

\end_inset

 provides a Laplace's approximation implementation
\begin_inset Foot
status open

\begin_layout Plain Layout
based on 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://iminuit.readthedocs.io/
\end_layout

\end_inset

, see 
\begin_inset CommandInset citation
LatexCommand cite
key "iminuit,James:1975dr"
literal "false"

\end_inset


\end_layout

\end_inset

, which can be improved with Gaussian mixtures learned by variational Bayes
 and importance sampling 
\begin_inset Foot
status open

\begin_layout Plain Layout
based on 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/pypmc/pypmc
\end_layout

\end_inset

, see 
\begin_inset CommandInset citation
LatexCommand cite
key "Beaujean2013"
literal "false"

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
It is interesting to firstly try to understand in which regions of the parameter
 space an inference algorithm gives reliable results.
 This is achievable with problems where the truth is known (toy problems
 or generated data sets).
 Only a subsequent step is performance comparison among reliable algorithms.
 To this end, we point out a few guidelines for comparing Bayesian samplers
 fairly.
 Initially, the full sample of problems presented here should be considered.
 If only a subset is of interest, this should be clearly and transparently
 stated (e.g., focus on low-dimensional inference problems, on mono-modal
 inference problems, etc.).
 It is a trivial statement that with more compute budget, a better accuracy
 and reliability can be achieved.
 Therefore, we recommend plotting bias or accuracy against computational
 cost for each algorithm and runtime.
 One quantifier of computational cost is the number of (likelihood) model
 evaluations or wall-clock time.
 The former is suitable for computationally challenging likelihoods, the
 latter is more relevant for computationally cheap models paired with algorithms
 that require costly training (such as deep neural networks).
 
\end_layout

\begin_layout Standard
It remains to be defined how to quantify the fidelity of the computation.
 To quantify posterior fidelity, see for example the probability-probability
 plots and Jensen-Shannon divergence quantification in 
\begin_inset CommandInset citation
LatexCommand cite
key "Romero-Shaw2020"
literal "false"

\end_inset

.
 However, the reliable retrieval of 
\begin_inset Formula $3\sigma$
\end_inset

 upper or lower parameter limits may also be of interest.
 Finally, when the true marginal likelihood 
\begin_inset Formula $Z$
\end_inset

 is known and can be tested against, recovering 
\begin_inset Formula $\ln Z$
\end_inset

 to an accuracy much better than 
\begin_inset Formula $\sim0.3$
\end_inset

 may not be useful in the context of Bayes factors, as it only mildly affects
 the interpretation.
\end_layout

\begin_layout Subsection
Future work
\end_layout

\begin_layout Standard
Breakthrough progress in machine learning is typically driven by (1) open,
 large, high-quality data sets and (2) a clear formulation of a meaningful
 objective.
 Examples span from MNIST’s challenge of digitizing hand-drawn numbers to
 the Critical Assessment of Structure Prediction (CASP) 
\begin_inset CommandInset citation
LatexCommand citep
key "Moult1995"
literal "false"

\end_inset

 protein-folding challenge, recently met by AlphaFold 
\begin_inset CommandInset citation
LatexCommand citep
key "Jumper2021"
literal "false"

\end_inset

.
 The “Learning to learn by gradient descent by gradient descent” paper 
\begin_inset CommandInset citation
LatexCommand citep
key "Andrychowicz2016"
literal "false"

\end_inset

 demonstrated that optimization algorithms can be derived by machine learning.
 Perhaps a similar breakthrough can be accomplished for optimal Bayesian
 inference sampling procedures, by providing a open, large data base and
 a clear objective.
 To this end, the survey of inference problems encountered across cosmology,
 particle physics, astrophysics and astronomy is presented.
 The representative database includes fully specified likelihood and priors
 in a runnable docker image with python interfaces.
 While similar previous work has focusd on providing simplified models that
 serve as unit-tests 
\begin_inset CommandInset citation
LatexCommand citep
before "e.g.,"
key "inferencegym2020,Magnusson2021"
literal "false"

\end_inset

, this work uses real-world inference with the software pipelines employed
 by researchers.
\end_layout

\begin_layout Standard
As a first step, existing and novel algorithms can be judged across the
 parameter space of problems for their empirical behavior and robustness,
 and to make well-founded recommendation for specific applications.
 For more rapid testing and a unified interface, fast model emulators for
 the provided real-world examples would be useful.
 This is left for future work.
\end_layout

\begin_layout Standard
A step further into the future is comparable to Atari computer game playing
 artificial intelligences 
\begin_inset CommandInset citation
LatexCommand citep
key "Bellemare2012"
literal "false"

\end_inset

 that learn optimal game playing strategies with reinforcement learning:
 A playground for learning optimal Bayesian inference algorithms.
\end_layout

\begin_layout Acknowledgement
I thank Frederik Beaujean for insightful conversations.
 I thank Gana Moharram, who studied the IceCube neutrino analysis for a
 bachelor thesis with Philipp Eller, for insightful conversations.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "../../../../../PostDoc/literature/stats,/mnt/data/daten/PostDoc/literature/agn"
options "aa"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
appendix
\end_layout

\end_inset


\end_layout

\begin_layout Section
Real inference problems
\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "subsec:Real-problems"

\end_inset


\end_layout

\begin_layout Subsection
Cosmology with the Cosmic Microwave Background
\end_layout

\begin_layout Standard
(if you are a cosmologist, please help me with references!)
\end_layout

\begin_layout Standard
The Cosmic Microwave Background (CMB) is the oldest electromagnetic signal
 observable.
 It originated when the Universe underwent a transition from being so dense
 that photons would be constantly scattered to the current state where photons
 can travel freely.
 These photons allow us to measure the temperature of their regions of origin
 approximately 379,000 years after the Big Bang.
 A map of their emission over the sky gives information about the temperature
 correlation.
 This carries information of how the Big Bang inflation proceeded, which
 is dependent on important constituents of the Universe, such as the baryonic
 matter and dark matter content of the Universe.
 The CMB remains one of the most important experiments to measure cosmological
 parameters in the dark energy and cold dark matter cosmology framework
 (
\begin_inset Formula $\Lambda$
\end_inset

CDM).
 One difficulty in the fitting of cosmological models like 
\begin_inset Formula $\Lambda$
\end_inset

CDM to the CMB is that the prediction of angular correlations is computationally
 expensive (of the order of a few seconds per likelihood evaluation).
\end_layout

\begin_layout Standard
Here we adopt an example
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/JohannesBuchner/montepython_public/blob/3.5/input/example_ns.par
am
\end_layout

\end_inset


\end_layout

\end_inset

 of the MontePython cosmology fitting package
\begin_inset Foot
status open

\begin_layout Plain Layout
hosted at 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/brinckmann/montepython_public/
\end_layout

\end_inset


\end_layout

\end_inset

.
 We use the fake_planck_bluebook likelihood which emulates a Planck measurement.
 The free parameters are 
\begin_inset Formula $\Lambda$
\end_inset

CDM cosmological parameters, namely the baryonic density 
\begin_inset Formula $\Omega_{\mathrm{b}}$
\end_inset

 (between 1.8 and 3), the dark matter density 
\begin_inset Formula $\Omega_{\mathrm{cdm}}$
\end_inset

 (between 0.1 and 0.2), the scalar spectral index 
\begin_inset Formula $n_{s}$
\end_inset

 (between 0.9 and 1.1), 
\begin_inset Formula $A_{s}$
\end_inset

 (between 1.8 and 3), the hubble parameter value, relative to 
\begin_inset Formula $100\,\mathrm{km/s/Mpc}$
\end_inset

, 
\begin_inset Formula $h$
\end_inset

 (between 0.6 and 0.8), and the time of reionisation 
\begin_inset Formula $\tau_{\mathrm{reion}}$
\end_inset

 (between 0.004 and 0.12).
 All priors are uniform within the mentioned bounds.
\end_layout

\begin_layout Subsection
Gravitational wave analysis
\end_layout

\begin_layout Standard
Gravitational waves originate from distortions of space-time by compact
 objects.
 Recently, the development of multiple, extremely sensitive instruments
 have allowed the observation of two black holes merging.
 GW170817 
\begin_inset CommandInset citation
LatexCommand citep
key "Abbott2017"
literal "true"

\end_inset

 was the first gravitational event detected by three detectors and allowed
 for the first time localisation on the sky, albeit with substantial parameter
 degeneracies.
\end_layout

\begin_layout Standard
Here we adopt a tutorial example
\begin_inset Foot
status open

\begin_layout Plain Layout
based on 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/gwastro/PyCBC-Tutorials/blob/7f5ff8fdd40c5dce2237b6082e1755b4a
ba9b989/tutorial/inference_1_ModelsAndPEByHand.ipynb
\end_layout

\end_inset


\end_layout

\end_inset

 of the PyCBC gravitational wave analysis package 
\begin_inset CommandInset citation
LatexCommand citep
key "Nitz2023pycbc"
literal "false"

\end_inset

 .
 The merging system GW170817 is described by the mass ratio 
\begin_inset Formula $q$
\end_inset

, the chirp mass 
\begin_inset Formula $m_{\mathrm{chirp}}$
\end_inset

, which is a combination of the two masses that influences the signal amplitude,
 the inclination 
\begin_inset Formula $i$
\end_inset

 of the system relative to the observer, the time of coalescence 
\begin_inset Formula $t_{c}$
\end_inset

 in seconds, the distance 
\begin_inset Formula $d$
\end_inset

 and position on the sky (
\begin_inset Formula $RA$
\end_inset

, 
\begin_inset Formula $DEC$
\end_inset

).
 The priors adopted are:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
q & \sim & \mathrm{Uniform}(1,2)\\
m_{\mathrm{chirp}} & \sim & \mathrm{Uniform}(1,2)\\
\sin i & \sim & \mathrm{Uniform}(0,1)\\
t_{c}-t_{m} & \sim & \mathrm{Uniform}(0.02,0.05)\\
d & \sim & \mathrm{Uniform}(10,100)\\
RA & \sim & \mathrm{Uniform}(0,2\pi)\\
\cos DEC & \sim & \mathrm{Uniform}(-1,1)
\end{align*}

\end_inset

where 
\begin_inset Formula $t_{m}$
\end_inset

 is the time automatically associated by an automated pipeline searching
 for candidate events in the noise.
\end_layout

\begin_layout Subsection
Atmospheric Neutrino Oscillations from IceCube
\end_layout

\begin_layout Standard
IceCube is a neutrino detector near the south pole, which has collected
 atmospheric neutrino data 
\begin_inset CommandInset citation
LatexCommand citep
key "Aartsen2018,Aartsen2018,2019PhRvD..99c2007A,Aartsen2020"
literal "false"

\end_inset

 that can be studied for neutrino oscillation.
 Here we adopt a tutorial example of the PISA IceCube analysis package
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
based on 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/icecube/pisa/blob/f91224b58360ee9ecefe4bdb232249263c9eee17/pis
a_examples/IceCube_3y_oscillations_example.ipynb
\end_layout

\end_inset


\end_layout

\end_inset

 applied to three-year IceCube data, where the muon and neutrinos model
 predicts a 2d-histogrammed signal, which is compared to collected data.
 The parameters are adopted from the PISA defaults:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathrm{nue\_umu\_ratio} & \sim & \mathrm{Gauss}(1,\,0.05)\\
\mathrm{Barr\_uphor\_ratio} & \sim & \mathrm{Gauss}(0,\,1)\\
\mathrm{Barr\_nu\_nubar\_ratio} & \sim & \mathrm{Gauss}(0,\,1)\\
\mathrm{delta\_index} & \sim & \mathrm{Gauss}(0,\,0.1)\\
\mathrm{theta13} & \sim & \mathrm{Gauss}(8.5°,\,0.205°)\\
\mathrm{theta23} & \sim & \mathrm{Uniform}(31°,\,59°)\\
\mathrm{deltam31} & \sim & \mathrm{Uniform}(0.001\,\mathrm{eV},\,0.007\,\,\mathrm{eV})\\
\mathrm{aeff\_scale} & \sim & \mathrm{Uniform}(0,\,3)\\
\mathrm{nutau\_norm} & \sim & \mathrm{Uniform}(-1,\,8.5)\\
\mathrm{nu\_nc\_norm} & \sim & \mathrm{Gauss}(1,\,0.2)\\
\mathrm{opt\_eff\_overall} & \sim & \mathrm{Gauss}(1,\,0.1)\\
\mathrm{opt\_eff\_lateral} & \sim & \mathrm{Gauss}(25,\,10)\\
\mathrm{opt\_eff\_headon} & \sim & \mathrm{Uniform}(-5,\,2)\\
\mathrm{ice\_scattering} & \sim & \mathrm{Gauss}(0,\,10)\\
\mathrm{ice\_absorption} & \sim & \mathrm{Gauss}(0,\,10)\\
\mathrm{atm\_muon\_scale} & \sim & \mathrm{Uniform}(0,\,5)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Gamma-rays from the Crab pulsar-wind nebula
\end_layout

\begin_layout Standard
The Crab nebula is the brightest astrophysical source in the sky at high
 energies.
 The Large-Area Telescope (LAT) onboard Fermi has observed emission from
 the region, which is a super-position of the Crab Pulsar (PSR J0534+2200),
 and synchrotron and Inverse Compton emission from the Crab Nebular.
 We follow the tutorial 
\begin_inset Foot
status open

\begin_layout Plain Layout
based on 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://threeml.readthedocs.io/en/stable/notebooks/Fermipy_LAT.html
\end_layout

\end_inset


\end_layout

\end_inset

 of the 3ML multi-messenger package .
\end_layout

\begin_layout Standard
All parameters are assigned uninformative priors.
 The parameters include the normalisation (uniform from 0 to 
\begin_inset Formula $1.4\times10^{10}\mathrm{keV}^{-1}\mathrm{s}^{-1}\mathrm{cm}^{-2}$
\end_inset

) and spectral index (uniform from -10 to 10) of the 
\begin_inset Quotes eld
\end_inset

super_cutoff_powerlaw
\begin_inset Quotes erd
\end_inset

 model for PSR
\begin_inset space ~
\end_inset

J0534+2200, the normalisation for the power law spectrum of NVSS
\begin_inset space ~
\end_inset

J052622+224801 (log-uniform from 
\begin_inset Formula $10^{-20}$
\end_inset

 to 
\begin_inset Formula $1.1\times10^{-14}$
\end_inset

) and 4FGL
\begin_inset space ~
\end_inset

J0544.4+2238 (log-uniform from 
\begin_inset Formula $10^{-20}$
\end_inset

 to 
\begin_inset Formula $1.39\times10^{-13}$
\end_inset

), and the isotropic background normalization and the galactic background
 factor.
 
\end_layout

\begin_layout Subsection
Exoplanet transit observations
\end_layout

\begin_layout Standard
Photometric light curves of stars can show small, periodic dips in brightness,
 which are interpreted as transits of exoplanets in front of the star.
 We follow the tutorial of the juliet package
\begin_inset Foot
status open

\begin_layout Plain Layout
based on 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://juliet.readthedocs.io/en/latest/tutorials/transitfits.html#transit-fits
\end_layout

\end_inset


\end_layout

\end_inset

 to analyse HATS-46 light curve observed with the Transiting Exoplanet Survey
 Satellite 
\begin_inset CommandInset citation
LatexCommand citep
after "for details"
before "see"
key "Brahm2018"
literal "false"

\end_inset

.
 The model is essentially a constant light curve modified by a U-shaped
 dip that repeats with some period.
 We use juliet 
\begin_inset CommandInset citation
LatexCommand citep
key "Espinoza2019juliet"
literal "false"

\end_inset

 for the implementation, which in turn uses batman 
\begin_inset CommandInset citation
LatexCommand citep
key "Kreidberg2015"
literal "false"

\end_inset

 for the light curve modelling together with limb-darkening 
\begin_inset CommandInset citation
LatexCommand citep
key "Kipping2013"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
The model parameters include the properties of the planet (period P in days,
 time-of-transit center t0, planet-to-star radius ratio p, eccentricity
 ecc, argument of periastron passage omega), as well as nuisance parameters
 (dilution factor mdilution, offset relative flux mflux, jitter sigma, Limb-dark
ening parameters q1 and q2):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathrm{P\_p1} & \sim & \mathrm{Gauss}(4.7,\,0.1)\\
\mathrm{t0\_p1} & \sim & \mathrm{Gauss}(1358.4,\,0.1)\\
\mathrm{r1\_p1} & \sim & \mathrm{Uniform}(0,\,1)\\
\mathrm{r2\_p1} & \sim & \mathrm{Uniform}(0,\,1)\\
\mathrm{q1\_TESS} & \sim & \mathrm{Uniform}(0,\,1)\\
\mathrm{q2\_TESS} & \sim & \mathrm{Uniform}(0,\,1)\\
\mathrm{ecc\_p1} & = & 0\\
\mathrm{omega\_p1} & = & 90\\
\mathrm{rho} & \sim & \mathrm{LogUniform}(100,\,10000)\\
\mathrm{mdilution\_TESS} & = & 1.0\\
\mathrm{mflux\_TESS} & \sim & \mathrm{Gauss}(0,\,0.1)\\
\mathrm{sigma\_w\_TESS} & \sim & \mathrm{LogUniform}(0.1,\,1000)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Exoplanet detection from Radial Velocity data
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename /home/user/Downloads/integration-problem-set/exoplanet/rvs_0005.txt.pdf
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Sine-data-1"

\end_inset

Exoplanet Doppler shift time series data (blue).
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
One of the most efficient ways to detect exoplanets is through changes in
 the line-of-sight (radial) velocity of individual stars, as the tug of
 planets gravitationally accelerates them (Doppler shift).
 A planetary system leads to a complex overlay of periodic velocity changes.
 Additionally, the measurement of velocities is uncertain, in part because
 of the instrument accuracy and precision, and in part because the spectral
 emission lines used to measure Doppler shifts can be unstable due to stellar
 activity.
 That latter process has been modeled with Gaussian processes in recent
 years.
\end_layout

\begin_layout Standard
Here we adopt the problem setup of the Extreme Precision Radial Velocity
 III challenge
\begin_inset Foot
status open

\begin_layout Plain Layout
hosted at 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/EPRV3EvidenceChallenge/Inputs
\end_layout

\end_inset


\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand citep
key "Nelson2020"
literal "false"

\end_inset

.
 They simulated several artificial exoplanet systems containing two planets,
 with a Gaussian process and realistic observation time sampling.
 The challenge participants were asked to compute the Bayesian marginal
 likelihoods of each data set assuming that the true number of planets was
 0, 1, 2 or 3.
 Participants did not know the true simulation input, but they were told
 the exact Gaussian noise properties, which follows a Gaussian process.
 Here we repeat this exercise, for their dataset 5 (shown in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Sine-data-1"

\end_inset

).
 The exact specification of this problem is defined in 
\begin_inset CommandInset citation
LatexCommand citep
key "Nelson2020"
literal "false"

\end_inset

.
 Essentially, it is similar to a sine time series fit, except that the periodic
 signal can be asymmetric due to ellipticity, giving 5 parameters per planet
 (signal amplitude, period, pericenter time, eccentricity and mean anomaly)
 that describe a Keplerian orbit.
 Additionally, the white noise amplitude 
\begin_inset Formula $\sigma_{j}$
\end_inset

 and the systematic velocity 
\begin_inset Formula $C$
\end_inset

 are free parameters, giving 
\begin_inset Formula $2+N_{\mathrm{planets}}\times5$
\end_inset

 free parameters for 
\begin_inset Formula $N_{\mathrm{planets}}=0,1,2,3$
\end_inset

.
 We use juliet 
\begin_inset CommandInset citation
LatexCommand citep
key "Espinoza2019juliet"
literal "false"

\end_inset

 for the implementation, which in turn uses RadVel 
\begin_inset CommandInset citation
LatexCommand citep
key "Fulton2018"
literal "false"

\end_inset

 for Kepler orbits and george 
\begin_inset CommandInset citation
LatexCommand citep
key "Ambikasaran2014"
literal "false"

\end_inset

 for modelling Gaussian processes.
\end_layout

\begin_layout Subsection
X-ray spectral analysis of Active Galactic Nuclei
\end_layout

\begin_layout Standard
Active Galactic Nuclei (AGN) are regions in the centres of massive galaxies
 where super-massive black holes grow.
 As gas swirls into the black hole, enormous amounts of radiation are produced
 by release of gravitational energy, sometimes shining brighter than all
 host galaxy stars together.
 Close to the black hole, X-rays are also produced and are an important
 tracer of the mass inflow into the black hole.
 They also allow identifying AGN in the sky, even when the black hole is
 surrounded by thick gas and dust, as most of the energetic X-rays penetrate
 through any obscurers.
 Space-based X-ray focusing instruments allow measurements of the X-ray
 spectra, which carry information on the AGN luminosity, obscuring column
 density and properties of the X-ray emitter (photon index, energy turn-over).
 The detection of X-ray radiation is performed by counting photon events
 and capturing an estimate of their energy, time of arrival and location
 on the sky.
 However, the energy response and energy-dependent sensitivity of the instrument
 adds some analysis complexity.
 Additionally, when few counts are detected per energy bin, as is commonly
 the case, the process needs to be modelled with a Poisson likelihood.
 For more details, see 
\begin_inset CommandInset citation
LatexCommand citet
key "Buchner2014"
literal "false"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand citet
key "Dyk2001"
literal "false"

\end_inset

.
\end_layout

\begin_layout Standard
Here, we include the source of a Chandra deep observation (source ID 179)
 presented 
\begin_inset CommandInset citation
LatexCommand citet
key "Buchner2014"
literal "false"

\end_inset

.
 The data are available online
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/JohannesBuchner/BXA/tree/master/examples/sherpa
\end_layout

\end_inset


\end_layout

\end_inset

 and the model is defined by the xagnfitter script
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://johannesbuchner.github.io/BXA/xagnfitter.html
\end_layout

\end_inset


\end_layout

\end_inset

 of the Bayesian X-ray analysis package 
\begin_inset CommandInset citation
LatexCommand citep
before "BXA;"
key "Buchner2021"
literal "false"

\end_inset

 based on sherpa 
\begin_inset CommandInset citation
LatexCommand citep
key "Freeman2001"
literal "false"

\end_inset

.
 The intrinsic X-ray emission is a powerlaw, which is modulated by a physical
 obscurer model simulation of photo-electric absorption, Compton-scattering
 and fluorescent line-emission 
\begin_inset CommandInset citation
LatexCommand citep
key "Buchner2019a"
literal "false"

\end_inset

.
 This model is available as a table
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/JohannesBuchner/xars/blob/master/doc/uxclumpy.rst
\end_layout

\end_inset


\end_layout

\end_inset

.
 To this obscured AGN model, a soft, unobscured powerlaw is added.
 The background spectrum is added and its normalisation determined simultaneousl
y with a joint fit of the spectrum extracted in a background sky region
 and the source+background spectrum extracted at the source location.
 The model has four parameters.
 This includes a wide log-uniform prior (between 
\begin_inset Formula $10^{-8}$
\end_inset

 and 
\begin_inset Formula $10^{-3}$
\end_inset

) on the powerlaw normalisation, a wide log-uniform prior (between 
\begin_inset Formula $10^{-7}$
\end_inset

 and 
\begin_inset Formula $10^{-1}$
\end_inset

) on the soft power law normalisation relative to the primary powerlaw normalisa
tion, intrinsic power law, a Gaussian prior on the power law photon index
 with mean 1.95 and standard deviation 0.15, a log-uniform prior on the obscurer
 column density between 
\begin_inset Formula $10^{20}$
\end_inset

 and 
\begin_inset Formula $10^{26}/\mathrm{cm}^{2}$
\end_inset

.
\end_layout

\begin_layout Subsection
Superluminous supernova
\end_layout

\begin_layout Standard
Super-Luminous Supernovae (SLSN) are extreme explosions at the end of stellar
 evolution.
 By fitting photometric observations over time, the explosion mechanism
 and its physical parameters can be determined (and distinguished from other
 transients).
 We follow the tutorial of MOSFiT 
\begin_inset Foot
status open

\begin_layout Plain Layout
based on 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://mosfit.readthedocs.io/en/latest/fitting.html#public-data
\end_layout

\end_inset


\end_layout

\end_inset

, to analyse LSQ12dlf, with two models described in 
\begin_inset CommandInset citation
LatexCommand cite
key "Nicholl2017"
literal "false"

\end_inset

: a magnetar engine with a simple spectral energy distribution (`magnetar`
 model) and a magnetar with a modified spectrum and additional constraints
 (`slsn` model).
 The parameters are:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathrm{nhhost} & \sim & \mathrm{LogUniform}(10^{16},\,10^{23})\\
\mathrm{Pspin} & \sim & \mathrm{Uniform}(1,\,10)\\
\mathrm{Bfield} & \sim & \mathrm{LogUniform}(0.1,\,10)\\
\mathrm{Mns} & \sim & \mathrm{Uniform}(1,\,2)\\
\mathrm{thetaPB} & \sim & \mathrm{Uniform}(0,\,1.5708)\\
\mathrm{texplosion} & \sim & \mathrm{Uniform}(-500,\,0)\\
\mathrm{kappa} & \sim & \mathrm{Uniform}(0.05,\,0.2)\\
\mathrm{kappagamma} & \sim & \mathrm{LogUniform}(0.1,\,10000)\\
\mathrm{mejecta} & \sim & \mathrm{LogUniform}(0.001,\,100)\\
\mathrm{vejecta} & \sim & \mathrm{Uniform}(5000,\,20000)\\
\mathrm{temperature} & \sim & \mathrm{LogUniform}(1000,\,100000)\\
\mathrm{variance} & \sim & \mathrm{LogUniform}(0.001,\,100)\\
\mathrm{codeltatime} & \sim & \mathrm{LogUniform}(0.001,\,100)\\
\mathrm{codeltalambda} & \sim & \mathrm{LogUniform}(0.1,\,10000)
\end{align*}

\end_inset

In case of `slsn`, the following parameters differ:
\begin_inset Formula 
\begin{align*}
\mathrm{Bfield} & \sim & \mathrm{Uniform}(0.1,\,10)\\
\mathrm{mejecta} & \sim & \mathrm{LogUniform}(0.1,\,100)\\
\mathrm{vejecta} & \sim & \mathrm{Uniform}(5000,\,20000)\\
\mathrm{temperature} & \sim & \mathrm{Uniform}(3000,\,10000)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsection
Gamma-ray burst
\end_layout

\begin_layout Plain Layout
The Gamma-ray burst 080916C was detected by the Gamma-ray Burst Monitor
 (GBM) onboard Fermi.
 The burst was very bright, allowing time-resolved analysis of the gamma-ray
 spectrum.
 In this analysis, the light curve was first split into time segments.
 Each segment is fit with an empirical bending spectral function, which
 has the following parameters to control the low and high-energy slopes,
 the knee location in energy and flux normalisation:
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{align*}
\alpha & \sim & \mathrm{Gauss}(-1,0.5)\times\mathrm{Uniform}(-1.5,\,1)\\
\beta & \sim & \mathrm{Gauss}(-2,0.5)\times\mathrm{Uniform}(-5,\,-1.6)\\
\mathrm{xp} & \sim & \mathrm{LogNormal}(2,\,1)\\
\mathrm{K} & \sim & \mathrm{LogUniform}(10^{-10},\,10^{3})
\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Lennard-Jones potential
\end_layout

\begin_layout Standard
In material science, the group behaviour of atoms gives rise to structures
 and phases of matter (solids, liquids, gases, crystals, metals, etc).
 A standard example is the Lennard-Jones potential, which we adopt here
 with 6 particles in a box.
 Pairs of particles feel two forces, a repulsive force at short distances
 (Pauli repulsion) and an attractive force at longer distances (van der
 Waals force).
 This are formulated as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
{\cal L}=\prod_{i}\prod_{j>i}\left(\frac{\sigma}{r_{ij}}\right)^{6}-\left(\frac{\sigma}{r_{ij}}\right)^{12}
\]

\end_inset

where 
\begin_inset Formula $r_{ij}$
\end_inset

 is the Euclidean distance between particles with indices 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

, but at least 
\begin_inset Formula $\sigma$
\end_inset

.
 We set 
\begin_inset Formula $\sigma=10^{-3}$
\end_inset

, which defines the scale at which particles feel attraction or repulsion.
 
\end_layout

\begin_layout Standard
Each particle's three-dimensional location (x,y,z) is a free parameter between
 -1 and +1.
 To avoid identical modes, we set the likelihood to zero when 
\begin_inset Formula $|z_{1}|<|z_{2}|<...<|z_{n}|$
\end_inset

 is not satisfied.
 Due to translation symmetry, we assume the first particle is placed in
 the coordinate centre (0,0,0).
 From rotation symmetry, we assume the second particle is placed along the
 positive z direction (0,0,
\begin_inset Formula $z_{2}$
\end_inset

).
 From a second rotation symmetry, the third particle is placed on the (0,
\begin_inset Formula $y_{3}$
\end_inset

,
\begin_inset Formula $z_{3}$
\end_inset

) plane.
 The remaining particles have all (x,y,z) coordinates as free parameters.
\end_layout

\begin_layout Subsection
Power-law line fit: Tully-Fisher relation
\end_layout

\begin_layout Standard
Stars in the centres of galaxies move akin to a ideal gas, so that the velocity
 dispersion of galactic central elliptical components (bulges) correlates
 with the bulge mass.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Kormendy2013"
literal "false"

\end_inset

 presented a compilation of measurements of velocity dispersions and masses,
 both annotated with asymmetric (and heteroscedastic) error bars.
 Following the 
\begin_inset Quotes eld
\end_inset

Fitting a line
\begin_inset Quotes erd
\end_inset

 tutorial
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://johannesbuchner.github.io/UltraNest/example-line.html
\end_layout

\end_inset


\end_layout

\end_inset

 of UltraNest, we assume these correspond to Gaussian tails, scaled according
 to the error bar size.
 The measurements are fit with a powerlaw, with the intrinsic scatter along
 the powerlaw accounted for by a log-Normal distribution.
 The parameters are
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\mathrm{slope} & \sim & \mathrm{Uniform}(-3,\,3)\\
\mathrm{offset} & \sim & \mathrm{LogUniform}(10,\,1000)\\
\mathrm{scatter} & \sim & \mathrm{LogUniform}(0.001,\,10)
\end{align*}

\end_inset

The likelihood is integrating the Log-Normal distribution over the data
 point distribution, i.e., it is a hierarchical Bayesian model.
 This integration is performed numerically.
\end_layout

\begin_layout Subsection
Sample distributions: A galaxy without dark matter
\end_layout

\begin_layout Subsubsection
Gaussian Sample distribution
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "vanDokkum2018"
literal "false"

\end_inset

 observed the velocity of globular clusters in a low-mass, ultra-diffuse
 galaxy.
 The width of the (Gaussian) distribution of velocities, i.e., the velocity
 dispersion, is directly related to the total galaxy mass.
 From comparing the stellar light to the total light, they inferred that
 the dark matter mass in this galaxy is negligible.
 Following 
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://johannesbuchner.github.io/UltraNest/example-intrinsic-distribution.html
\end_layout

\end_inset


\end_layout

\end_inset

, we analyse their velocity measurements with Gaussian error bars, assuming
 a Gaussian sample distribution (see e.g., 
\begin_inset CommandInset citation
LatexCommand citealp
key "Baronchelli2018"
literal "false"

\end_inset

 for such a Gaussian hierarchical model in astronomy).
 The parameters are the mean, for which we assume a uniform distribution
 between -100 and 100 km/s, and the scatter, for which we assume a log-uniform
 distribution between 1 and 1000 km/s.
 The parameter for each data point's true value is integrated out, as implemente
d in 
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/JohannesBuchner/PosteriorStacker
\end_layout

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Subsubsection
Dirichlet sample distribution
\end_layout

\begin_layout Standard
The above example is repeated, but with a more flexible sample distribution.
 Following the PosteriorStacker tutorial
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset Flex URL
status open

\begin_layout Plain Layout

https://github.com/JohannesBuchner/PosteriorStacker
\end_layout

\end_inset


\end_layout

\end_inset

, a uniform Dirichlet distribution is adopted, with 11 uniformly spaced
 bins between -80 km/s and +80 km/s.
 This analysis allows checking whether a Gaussian was a reasonable model.
\end_layout

\begin_layout Section
Mock problems
\begin_inset CommandInset label
LatexCommand label
name "sec:Mock-problems"

\end_inset


\end_layout

\begin_layout Subsection
Sine time series
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename sine.pdf
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Sine-data"

\end_inset

Sine time series data (orange) with generating two-component model.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Analyses of inhomogeneously sampled light curves is a common problem in
 astrophysics, sometimes with complex noise processes and semi-periodic
 signals.
 Here we present a simple multi-component sine signal as a toy problem,
 and uniformly randomly sample observing times.
 The problem is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log L & = & \prod_{i=1}^{M}\mathrm{Normal}(m(t_{i},\theta)-d_{i},\sigma^{2})\\
m(t,\theta) & = & m_{0}+\sum_{j=1}^{n_{\mathrm{comp}}}A_{c}\times\sin\left(\frac{2\pi t}{P_{j}}+\phi_{j}\right)\\
m_{0} & \sim & \mathrm{Uniform}(-50,50)\\
\log\sigma & \sim & \mathrm{Uniform}(-1.5,-0.5)\\
\log A & \sim & \mathrm{Uniform}(-2,2)\\
\phi & \sim & \mathrm{Uniform}(0,2\pi)\\
\log P & \sim & \mathrm{Uniform}(-1,3)
\end{align*}

\end_inset

Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Sine-data"

\end_inset

 presents a graph 
\begin_inset Formula $(t_{i},d_{i})$
\end_inset

 of 
\begin_inset Formula $M=40$
\end_inset

 data points, generated by sampling 
\begin_inset Formula $n_{\mathrm{comp}}=2$
\end_inset

 components with offset 
\begin_inset Formula $m_{0}=-5$
\end_inset

, measurement uncertainty 
\begin_inset Formula $\sigma=0.1$
\end_inset

, amplitudes 
\begin_inset Formula $A_{1}=0.25$
\end_inset

, 
\begin_inset Formula $A_{2}=0.05$
\end_inset

, periods 
\begin_inset Formula $P_{1}=180$
\end_inset

, 
\begin_inset Formula $P_{2}=44$
\end_inset

 and phases 
\begin_inset Formula $\phi_{1}=0$
\end_inset

, 
\begin_inset Formula $\phi_{2}=1\,\mathrm{rad}$
\end_inset

.
 The same data are analysed with 
\begin_inset Formula $n_{\mathrm{comp}}=0,\,1,\,2,\,3$
\end_inset

, producing two to eleven dimensional problems with completely exchangable
 components.
\end_layout

\begin_layout Subsection
Low X-ray count observations of a Compton-thick AGN
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../xrayspectrum.pdf
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:xraydata"

\end_inset

X-ray spectrum with the true generating model.
 The total model (blue curve) is a sum of two powerlaws, one altered by
 a exponential truncation towards the low-energy side.
 That model is multiplied by the instrument sensitivity (gray curve), and
 background contamination (red) is added.
 The final model is shown in blue, from which poisson data are drawn (green
 crosses).
\end_layout

\end_inset


\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
This mock problem (`xrayspectrum`) describes a 5-dimensional degenerate
 physical parameter space discussed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Buchner2014"
literal "false"

\end_inset

 of a heavily obscured active galactic nucleus.
 The model components and data are described in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:xraydata"

\end_inset

.
 The emission spectrum over 200 energy channels from 0.5 to 8
\begin_inset space ~
\end_inset

keV is described by:
\begin_inset Formula 
\[
F(E)=B+A_{LE}(E)\times E^{-\Gamma}\times\left[\exp\left(-N_{\mathrm{H}}\times E^{-3}\right)+f_{\mathrm{scat}}\right]
\]

\end_inset

with background amplitude 
\begin_inset Formula $B$
\end_inset

, signal amplitude 
\begin_inset Formula $A$
\end_inset

, spectral photon index 
\begin_inset Formula $\Gamma$
\end_inset

, obscuring column density 
\begin_inset Formula $N_{H}$
\end_inset

, and fraction of the powerlaw that escapes unobscured 
\begin_inset Formula $f_{\mathrm{scat}}$
\end_inset

.
 The instrument sensitivity peaks near 2keV: 
\begin_inset Formula $A_{LE}(E)=\exp\left\{ -\left|\frac{E-2\mathrm{keV}}{2\mathrm{keV}}\right|\right\} $
\end_inset

.
\end_layout

\begin_layout Standard
This model shows a degeneracy when 
\begin_inset Formula $A$
\end_inset

 is low and comparable to 
\begin_inset Formula $B$
\end_inset

, because high 
\begin_inset Formula $N_{H}$
\end_inset

 and high 
\begin_inset Formula $f_{\mathrm{scat}}$
\end_inset

 look like 
\begin_inset Formula $N_{H}=0$
\end_inset

 (a simple powerlaw).
 The model is illustrated in Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:xraydata"

\end_inset

.
 The priors on the parameters are:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log A & \sim & \mathrm{Uniform}(-5,+5)\\
\Gamma & \sim & \mathrm{Normal}(2,0.2^{2})\\
\text{\ensuremath{\log N_{\mathrm{H}}}} & \sim & \mathrm{Uniform}(-3,+3)\\
\log f_{\mathrm{scat}} & \sim & \mathrm{Uniform}(-7,-1)\\
\ln B & \sim & \mathrm{Normal}(0.2,0.1^{2})
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Toy problems
\begin_inset CommandInset label
LatexCommand label
name "sec:Toy-problems"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "subsec:Toy-problems"

\end_inset


\end_layout

\begin_layout Standard
In this section, the prior is the unit hypercube (
\begin_inset Formula $0<\theta_{i}<1$
\end_inset

 for 
\begin_inset Formula $1\leq i\leq d$
\end_inset

), unless specified otherwise.
 If analytically known, the marginal parameter posterior distribution 
\begin_inset Formula $p(\theta_{i}|D)$
\end_inset

 and marginal likelihood 
\begin_inset Formula $Z$
\end_inset

 are given.
\end_layout

\begin_layout Subsection
Asymmetric Gaussian
\end_layout

\begin_layout Standard
Integration of a Gaussian distribution is a standard test problem.
 The variation here introduces some parameter inequality and spreads the
 means in a sine pattern, so that the posterior is not at the center of
 the prior range.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
L & = & \prod_{i=1}^{d}\mathrm{Normal}(\mu_{i},\sigma_{i}^{2})\\
\sigma_{i} & = & 0.1\times10^{-\left(-9-\frac{\sqrt{d}}{2}\right)\times\frac{i-1}{d-1}}\\
\mu_{i} & = & \frac{1}{2}+\frac{1-5\sigma_{i}}{2}\times\sin\frac{i-1}{2d}
\end{align*}

\end_inset

This problem is evaluated using uniform priors on 
\begin_inset Formula $d=4$
\end_inset

 (making 
\begin_inset Formula $\sigma_{i}$
\end_inset

 range from 
\begin_inset Formula $10^{-9}$
\end_inset

 to 
\begin_inset Formula $10^{-1}$
\end_inset

), 
\begin_inset Formula $16$
\end_inset

 (
\begin_inset Formula $10^{-8}<\sigma_{i}<10^{-1}$
\end_inset

) and 
\begin_inset Formula $100$
\end_inset

 dimensions (
\begin_inset Formula $10^{-5}<\sigma_{i}<10^{-1}$
\end_inset

).
 The four-dimensional case is shown in the top left panel of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

.
 Note the different axes ranges.
 The true posterior is 
\begin_inset Formula $p(\theta_{i}|D)=\mathrm{Normal}(\mu_{i},\sigma_{i}^{2})$
\end_inset

, and the marginal likelihood 
\begin_inset Formula $Z\approx1$
\end_inset

.
\end_layout

\begin_layout Subsection
Beta product
\end_layout

\begin_layout Standard
Diverse test problems can be generated by combining standard one-dimensional
 probability distributions.
 Here, the Beta distribution is used to represent diverse posterior shapes
 in each parameter:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
L & = & \prod_{i=1}^{d}\mathrm{Beta}(a_{i},b_{i})
\end{align*}

\end_inset

with fixed, known 
\begin_inset Formula $a$
\end_inset

,
\begin_inset Formula $b$
\end_inset

, randomly generated as:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log a_{i} & \sim & \mathrm{Uniform}(-1,1)\\
\log b_{i} & \sim & \mathrm{Uniform}(-1,1)
\end{align*}

\end_inset

This distribution can produce multiple modes (where 
\begin_inset Formula $a_{i}<1$
\end_inset

 and 
\begin_inset Formula $b_{i}<1$
\end_inset

), non-Gaussian tails.
 The likelihood is relatively uninformative on each parameter (completely
 non-informative when 
\begin_inset Formula $a_{i}=b_{i}=0$
\end_inset

).
 We test this problem in 2, 10 and 30 dimensions.
 The true marginal posteriors are given by 
\begin_inset Formula $P(\theta_{i}|D)=\mathrm{Beta}(a_{i},b_{i})$
\end_inset

, and the marginal likelihood is 
\begin_inset Formula $Z=1$
\end_inset

.
\end_layout

\begin_layout Subsection
Correlated Funnel
\end_layout

\begin_layout Standard
Neil's funnel is a standard test problem that represents features of hierarchica
l Bayesian models.
 It is a normal distribution with the standard deviation also a free parameter.
 This causes a funnel shape (see middle panel of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

) involving all parameters.
 Such non-affine correlations can sometimes be eased significantly by reparametr
izations which scale the unknown mean parameters by the standard deviation
 parameter 
\begin_inset CommandInset citation
LatexCommand cite
key "Betancourt2013"
literal "false"

\end_inset

.
 Here we use the correlated version of 
\begin_inset CommandInset citation
LatexCommand cite
key "Karamanis2020"
literal "false"

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
L & = & \prod_{i}\mathrm{Normal}(\mu_{i}-\gamma\times\mu_{i-1},\Sigma^{2})\\
\ln\sigma & \sim & \mathrm{Normal}(0,1)\\
\mu_{i} & \sim & \mathrm{Uniform}(-100,100)\\
\Sigma_{ij} & = & \begin{cases}
\sigma & \mathrm{if\,}i=j\\
\gamma\times\sigma & \mathrm{otherwise}
\end{cases}
\end{align*}

\end_inset

This problem is tested in 2, 10 and 50 dimensions with correlation strength
 
\begin_inset Formula $\gamma=0.95$
\end_inset

.
 The true marginal posteriors are 
\begin_inset Formula $p(\mu_{i}|D)=\mathrm{Normal}(0,1)$
\end_inset

, 
\begin_inset Formula $p(\ln\mu_{i}|D)=\mathrm{Normal}(0,1)$
\end_inset

, and the marginal likelihood 
\begin_inset Formula $Z\approx1$
\end_inset

.
\end_layout

\begin_layout Subsection
Rosenbrock function
\end_layout

\begin_layout Standard
The Rosenbrock function is a standard test problem in optimization.
 It exhibits a non-linear, narrow degeneracy that can be difficult to navigate
 (right middle panel of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

).
 We adopt a probabilistic formulation suggested by 
\begin_inset CommandInset citation
LatexCommand cite
key "RosenbrockChallenge"
literal "false"

\end_inset

 (see a similar version in 
\begin_inset CommandInset citation
LatexCommand cite
key "Jia2019"
literal "true"

\end_inset

):
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log L & = & -2\times\sum_{i=1}^{d-1}100\times\left(\theta_{i+1}-x_{i}^{2}\right)^{2}+\left(1-\theta_{i}\right)^{2}\\
\theta_{i} & \sim & \mathrm{Uniform}(-10,10)
\end{align*}

\end_inset

We test this problem in 2, 20 and 50 dimensions.
\end_layout

\begin_layout Subsection
LogGamma
\end_layout

\begin_layout Standard
The LogGamma problem 
\begin_inset CommandInset citation
LatexCommand cite
key "Beaujean2013"
literal "false"

\end_inset

 exhibits multi-modality and heavy tails, which lead to non-elliptical contours.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
g_{a} & \sim & \mathrm{LogGamma}\left(1,\,\frac{1}{3},\,\frac{1}{30}\right)\\
g_{b} & \sim & \mathrm{LogGamma}\left(1,\,\frac{2}{3},\,\frac{1}{30}\right)\\
n_{c} & \sim & \mathrm{Normal}\left(\frac{1}{3},\,\frac{1}{30}\right)\\
n_{d} & \sim & \mathrm{Normal}\left(\frac{2}{3},\,\frac{1}{30}\right)\\
d_{i} & \sim & \mathrm{LogGamma}\left(1,\,\frac{2}{3},\,\frac{1}{30}\right)\,\text{\,\,\ if\,\,\,}3\leq i\leq\frac{d+2}{2}\\
d_{i} & \sim & \mathrm{Normal}\left(\frac{2}{3},\,\frac{1}{30}\right)\,\text{\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\ if\,\,\,}\frac{d+2}{2}<i\\
L_{1} & = & \frac{1}{2}\left(g_{a}(x_{1})+g_{b}(x_{1})\right)\\
L_{2} & = & \frac{1}{2}\left(n_{c}(x_{2})+n_{d}(x_{2})\right)\\
L & = & L_{1}\times L_{2}\times\prod_{i=3}^{d}d_{i}(x_{i})
\end{eqnarray*}

\end_inset

We test this problem in 2, 10 and 30 dimensions.
 The true marginal posteriors are given by 
\begin_inset Formula $P(x_{1}|D)=L_{1}(x_{1})$
\end_inset

, and the marginal likelihood is 
\begin_inset Formula $Z=1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsubsection
AR(1) process
\end_layout

\begin_layout Plain Layout
A first-order auto-regressive process (AR(1)) can be used as a test problem
 of correlated parameters:
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{align*}
L & = & \mathrm{Normal}(x_{1},1)\prod_{i=1}^{d-1}\mathrm{Normal}(\mu_{i+1}-\alpha\mu_{i},\beta^{2})\\
\alpha & = & 0.95\\
\beta & = & \sqrt{1-\alpha^{2}}
\end{align*}

\end_inset

We test this problem in 2, 10 and 25 dimensions.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Eggbox
\end_layout

\begin_layout Standard
The eggbox function is a two-dimensional extremely multi-modal function
 (bottom left panel of Figure
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "fig:pairwise-posterior"

\end_inset

) proposed by 
\begin_inset CommandInset citation
LatexCommand cite
key "Feroz2008"
literal "false"

\end_inset

, defined as: 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\log L & = & \left(2+\cos(5\pi\cdot\theta_{1})\cdot\cos(5\pi\cdot\theta_{2})\right)^{5}\\
\theta_{i} & \sim & \mathrm{Uniform}(0,10\pi)
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Box
\end_layout

\begin_layout Standard
This is a flat distribution at the corner of the parameter space, placed
 on top of a wide, unimportant Gaussian distribution:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\ln L & = & -\frac{1}{2}\times\left(\frac{\theta}{0.1}\right)^{2}+100\times I[\delta<0.1]
\end{align*}

\end_inset

Here, 
\begin_inset Formula $\delta=\max_{i}|\theta_{i}|$
\end_inset

 is the parameter with the largest deviation from zero.
 The priors are the standard uniform distribution on all parameters 
\begin_inset Formula $\theta_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
We test this problem in 
\begin_inset Formula $d=5$
\end_inset

 dimensions.
 The true marginal posteriors are given by 
\begin_inset Formula $P(\theta_{i}|D)=\mathrm{Uniform}(0,0.1)$
\end_inset

, and the marginal likelihood is 
\begin_inset Formula $\ln Z\approx100+(0.1)^{d}$
\end_inset

.
 
\end_layout

\begin_layout Subsection
Spike and slab
\end_layout

\begin_layout Standard
The spike and slab problem is a mixture of two gaussians, one with a wide
 standard deviation, one with a narrow standard deviation.
 This leads to a strong phase transition.
 The narrower gaussian has standard deviation 
\begin_inset Formula $\sigma_{2}=f^{-\frac{1}{d}}$
\end_inset

, and is shifted by 
\begin_inset Formula $\Delta$
\end_inset

 in each direction.
 The wider gaussian has standard deviation 
\begin_inset Formula $\sigma_{1}=1$
\end_inset

.
 Then the likelihood is:
\begin_inset Formula 
\begin{eqnarray*}
L & = & L_{1}+L_{2}\\
L_{1} & = & \frac{w_{1}}{1+w_{1}}\prod_{i}\frac{1}{2\pi\sigma_{1}^{2}}\exp\left\{ -\frac{1}{2}\times\left(\frac{\theta_{i}-\Delta\times\sigma_{1}}{\sigma_{1}}\right)^{2}\right\} \\
L_{2} & = & \frac{1}{1+w_{1}}\prod_{i}\frac{1}{2\pi\sigma_{2}^{2}}\exp\left\{ -\frac{1}{2}\times\left(\frac{\theta_{i}}{\sigma_{2}}\right)^{2}\right\} 
\end{eqnarray*}

\end_inset

We use a two-dimensional setup, with the two Gaussians co-located 
\begin_inset Formula $\Delta=0$
\end_inset

.
 For the relative weights we adopt 
\begin_inset Formula $w_{1}$
\end_inset

 values of 1, 40, 1000, and for 
\begin_inset Formula $\sigma_{2}$
\end_inset

 adopt 4, 40, 400 or 4000.
 This gives 16 mono-modal toy problems with phase transitions.
 Secondly, we adopt offset values for 
\begin_inset Formula $\Delta$
\end_inset

 of 1, 2, 4, 10 with weights 
\begin_inset Formula $w_{1}$
\end_inset

 of 1, 40 or 1000.
 This gives another 8 (bimodal) toy problems.
 The problems are named 
\begin_inset Quotes eld
\end_inset

spikeslab-
\begin_inset Formula $w_{1}$
\end_inset

-
\begin_inset Formula $d$
\end_inset

d-
\begin_inset Formula $\sigma_{2}$
\end_inset

(-off
\begin_inset Formula $\Delta$
\end_inset

)
\begin_inset Quotes erd
\end_inset

.
 The parameters are uniformly distributed from -10 to +10.
\end_layout

\begin_layout Standard
The true evidence is 
\begin_inset Formula $Z=20^{-d}\approx e^{-6}$
\end_inset

 when 
\begin_inset Formula $\sigma_{2}$
\end_inset

 is small, and the true marginals are the superposition of the two weighted
 Gaussians.
 
\end_layout

\end_body
\end_document
